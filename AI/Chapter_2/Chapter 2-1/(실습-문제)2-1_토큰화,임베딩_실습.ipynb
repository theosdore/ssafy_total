{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f4b6a34",
   "metadata": {},
   "source": [
    "### **Content License Agreement**\n",
    "\n",
    "<font color='red'><b>**WARNING**</b></font> : ë³¸ ìë£ŒëŠ” ì‚¼ì„±ì²­ë…„SWÂ·AIì•„ì¹´ë°ë¯¸ì˜ ì»¨í…ì¸  ìì‚°ìœ¼ë¡œ, ë³´ì•ˆì„œì•½ì„œì— ì˜ê±°í•˜ì—¬ ì–´ë– í•œ ì‚¬ìœ ë¡œë„ ì„ì˜ë¡œ ë³µì‚¬, ì´¬ì˜, ë…¹ìŒ, ë³µì œ, ë³´ê´€, ì „ì†¡í•˜ê±°ë‚˜ í—ˆê°€ ë°›ì§€ ì•Šì€ ì €ì¥ë§¤ì²´ë¥¼ ì´ìš©í•œ ë³´ê´€, ì œ3ìì—ê²Œ ëˆ„ì„¤, ê³µê°œ ë˜ëŠ” ì‚¬ìš©í•˜ëŠ” ë“±ì˜ ë¬´ë‹¨ ì‚¬ìš© ë° ë¶ˆë²• ë°°í¬ ì‹œ ë²•ì  ì¡°ì¹˜ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5dacf",
   "metadata": {},
   "source": [
    "### **Objectives**\n",
    "\n",
    "1. ì‹¤ìŠµëª…: í† í°í™”/ì„ë² ë”© ì‹¤ìŠµ\n",
    "2. í•µì‹¬ ì£¼ì œ\n",
    "    1) tokenizerë¥¼ ì´ìš©í•˜ì—¬ ë‹¨ì–´ë“¤ì„ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì´í•´\n",
    "    2) í† í°í™”ëœ í† í°ë“¤ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì´í•´\n",
    "    3) RNNë¶€í„° íŠ¸ëœìŠ¤í¬ë¨¸ê¹Œì§€ ëª¨ë¸ì˜ ë°œì „ì‚¬ë¥¼ ì§ì ‘ ì²´í—˜í•˜ê³  ê° ìš”ì†Œ ê¸°ìˆ ì˜ ì—­í• ì„ ì´í•´\n",
    "3. í•™ìŠµ ëª©í‘œ\n",
    "    1) í† í¬ë‚˜ì´ì €ê°€ ë¬´ì—‡ì´ê³  í† í°í™”ê°€ ë¬´ì—‡ì¸ì§€ì— ëŒ€í•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
    "    2) í† í°í™”ë¥¼ ì™œ í•˜ëŠ”ì§€ì— ëŒ€í•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
    "    3) í† í°í™”ëœ í† í°ë“¤ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ì´í•´í•  ìˆ˜ ìˆë‹¤.\n",
    "    4) ì„ë² ë”© ë²¡í„°ë¥¼ ì´ìš©í•˜ì—¬ ì–´ë–¤ ì‹ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
    "    5) ë‹¤ì–‘í•œ ëª¨ë¸ì˜ ë°œì „ì‚¬ì— ëŒ€í•´ ì§ì ‘ ì²´í—˜í•˜ê³  ê° ì•„í‚¤í…ì³ê°€ ê°€ì§€ëŠ” íŠ¹ì§•ì„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "4. í•™ìŠµ ê°œë…\n",
    "    1) í† í°í™”: \n",
    "    2) ì„ë² ë”© ë²¡í„°: \n",
    "    3) ì¸ì½”ë”/ë””ì½”ë”: \n",
    "  \n",
    "5. í•™ìŠµ ë°©í–¥\n",
    "    - ì‹¤ìŠµì€ ì•„ë˜ ë‚´ìš©ë“¤ì„ ì§ì ‘ ì²´í—˜í•˜ê³  ê° ì•„í‚¤í…ì³ê°€ ê°€ì§€ëŠ” íŠ¹ì§•ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\n",
    "      - í† í°í™”\n",
    "      - ì„ë² ë”©\n",
    "      - RNN\n",
    "      - LSTM\n",
    "      - ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜\n",
    "      - ì¸ì½”ë”\n",
    "      - ë””ì½”ë”\n",
    "    - ì‹¤ìŠµ ì½”ë“œëŠ” ì¡°êµê°€ ì§ì ‘ êµ¬í˜„í•œ ì½”ë“œë¥¼ ì°¸ê³ í•˜ë©° í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "    - ìì—°ìŠ¤ëŸ½ê²Œ ì½”ë“œë¥¼ êµ¬í˜„í•˜ë©´ì„œ ì•„í‚¤í…ì³ì˜ ë°œì „ì‚¬ë¥¼ ì²´í—˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "6. ë°ì´í„°ì…‹ ê°œìš” ë° ì €ì‘ê¶Œ ì •ë³´\n",
    "    - ë°ì´í„°ì…‹ ëª… : NSMC(Naver Sentiment Movie Corpus)\n",
    "    - ë°ì´í„°ì…‹ ê°œìš” : ë„¤ì´ë²„ ì˜í™” ê°ì •ë¶„ì„ ë°ì´í„°ì…‹\n",
    "    - ë°ì´í„°ì…‹ ì €ì‘ê¶Œ : CC0 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26eeb4b",
   "metadata": {},
   "source": [
    "### **Prerequisites**\n",
    "```\n",
    "numpy==2.0.2\n",
    "pandas==2.2.2\n",
    "tokenizers==0.21.4\n",
    "transformers==4.55.2\n",
    "torch==2.8.0+cu126\n",
    "```\n",
    "\n",
    "- ë§Œì•½, ê¸°ë³¸ ì½”ë©ê³¼ ë²„ì „ì´ ë‹¤ë¥´ë‹¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ë³µì‚¬í•´ì„œ ì‹¤í–‰ì‹œì¼œì£¼ì„¸ìš”.\n",
    "```\n",
    "%pip install numpy==2.0.2 pandas==2.2.2 tokenizers==0.21.4 transformers==4.55.2 torch==2.8.0+cu126 --index-url https://download.pytorch.org/whl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1260a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import (\n",
    "    Generic,\n",
    "    Tuple,\n",
    "    TypeVar,\n",
    "    List,\n",
    "    Union,\n",
    "    get_args\n",
    ")\n",
    "# ì‹œë“œ ì„¤ì •\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "Batch = TypeVar(\"Batch\", bound=int)\n",
    "Token = TypeVar(\"Token\", bound=int)\n",
    "Sequence = TypeVar(\"Sequence\", bound=int)\n",
    "Layers = TypeVar(\"Layers\", bound=int)\n",
    "HiddenStates = TypeVar(\"HiddenStates\", bound=int)\n",
    "VocabSize = TypeVar(\"VocabSize\", bound=int)\n",
    "EmbeddingSize = TypeVar(\"EmbeddingSize\", bound=int)\n",
    "MaxLength = TypeVar(\"MaxLength\", bound=int)\n",
    "\n",
    "_1D = TypeVar(\"_1D\")\n",
    "_2D = TypeVar(\"_2D\")\n",
    "_3D = TypeVar(\"_3D\")\n",
    "\n",
    "def _label_str(self) -> str:\n",
    "    \"\"\"ì¸ìŠ¤í„´ìŠ¤ì˜ ì œë„¤ë¦­ ë¼ë²¨ ì´ë¦„ì„ ì˜ˆì˜ê²Œ í‘œì‹œ (e.g., [Sequence])\"\"\"\n",
    "    oc = getattr(self, \"__orig_class__\", None)\n",
    "    if oc is None:\n",
    "        return \"[]\"\n",
    "    args = get_args(oc)\n",
    "    names = [getattr(a, \"__name__\", str(a)) for a in args]\n",
    "    return \"[\" + \", \".join(names) + \"]\"\n",
    "\n",
    "\n",
    "class Tensor1D(Generic[_1D]):\n",
    "    def __init__(self, tensor: torch.Tensor):\n",
    "        assert tensor.dim() == 1, ValueError(\"Tensor must be 1-dimensional\")\n",
    "        self.tensor = tensor\n",
    "        self.s: _1D = tensor.size(0)  # sequence length\n",
    "\n",
    "    def size(self) -> Tuple[int, int]:\n",
    "        return self.tensor.size()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Tensor(shape=({self.s}))\"\n",
    "\n",
    "class Tensor2D(Generic[_1D, _2D]):\n",
    "    def __init__(self, tensor: torch.Tensor):\n",
    "        assert tensor.dim() == 2, ValueError(\"Tensor must be 2-dimensional\")\n",
    "        self.tensor = tensor\n",
    "        self.b: _1D = tensor.size(0)  # batch size\n",
    "        self.s: _2D = tensor.size(1)  # sequence length\n",
    "        assert self.b == tensor.size(0), ValueError(\n",
    "            f\"Expected batch {self.b}, but got {tensor.size(0)}\"\n",
    "        )\n",
    "        assert self.s == tensor.size(1), ValueError(\n",
    "            f\"Expected Sequence {self.s}, but got {tensor.size(1)}\"\n",
    "        )\n",
    "\n",
    "    def size(self) -> Tuple[int, int]:\n",
    "        return self.tensor.size()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Tensor(shape=({self.b}, {self.s}))\"\n",
    "\n",
    "\n",
    "class Tensor3D(Generic[_1D, _2D, _3D]):\n",
    "    def __init__(self, tensor: torch.Tensor):\n",
    "        assert tensor.dim() == 3, ValueError(\"Tensor must be 3-dimensional\")\n",
    "        self.tensor = tensor\n",
    "        self.b: _1D = tensor.size(0)  # batch size\n",
    "        self.s: _2D = tensor.size(1)  # sequence length\n",
    "        self.h: _3D = tensor.size(2)  # hidden state size\n",
    "        assert self.b == tensor.size(0), ValueError(\n",
    "            f\"Expected batch {self.b}, but got {tensor.size(0)}\"\n",
    "        )\n",
    "        assert self.s == tensor.size(1), ValueError(\n",
    "            f\"Expected Sequence {self.s}, but got {tensor.size(1)}\"\n",
    "        )\n",
    "        assert self.h == tensor.size(2), ValueError(\n",
    "            f\"Expected Hidden State {self.h}, but got {tensor.size(2)}\"\n",
    "        )\n",
    "\n",
    "    def size(self) -> Tuple[int, int]:\n",
    "        return self.tensor.size()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Tensor(shape=({self.b}, {self.s}, {self.h}))\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55eb901",
   "metadata": {},
   "source": [
    "# 1. í† í¬ë‚˜ì´ì € / ì›Œë“œ ì„ë² ë”©\n",
    "\n",
    "- í•™ìŠµ ëª©í‘œ\n",
    "  1. í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.\n",
    "  2. í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ í† í° ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ì´í•´í•˜ê³  êµ¬í˜„í•  ìˆ˜ ìˆã….\n",
    "- í•™ìŠµ ê°œë…\n",
    "  1. í† í¬ë‚˜ì´ì €\n",
    "  2. í† í°í™”\n",
    "  3. ì„ë² ë”©\n",
    "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
    "  1. ì œê³µëœ ë§ë­‰ì¹˜ë¡œ WordPiece í† í¬ë‚˜ì´ì €ë¥¼ í›ˆë ¨ì‹œí‚¤ëŠ” ì½”ë“œ í•œ ì¤„ì„ ì™„ì„±\n",
    "  2. í›ˆë ¨ëœ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ íŠ¹ì • ë¬¸ì¥ì„ í† í° ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ì½”ë“œ\n",
    "  3. nn.Embedding ë ˆì´ì–´(í˜¹ì€ ê°„ë‹¨í•œ dict lookup)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í† í° IDì— í•´ë‹¹í•˜ëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ ì¡°íšŒí•˜ëŠ” ì½”ë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42fdfec",
   "metadata": {},
   "source": [
    "### 1.1. Tokenizer í•™ìŠµ\n",
    "\n",
    "<blockquote>\n",
    "<b>ğŸ§  í† í¬ë‚˜ì´ì € í•™ìŠµ</b><br>\n",
    "ì–¸ì–´ ëª¨ë¸ì—ì„œ í† í¬ë‚˜ì´ì €ëŠ” í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
    "</blockquote>\n",
    "\n",
    "í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ìŒ ë‘ê°€ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "1. í† í¬ë‚˜ì´ì € ê°ì²´(í´ë˜ìŠ¤)\n",
    "2. í•™ìŠµ ë°ì´í„°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc62bac",
   "metadata": {},
   "source": [
    "ê·¸ëŸ¬ë©´ ìš°ì„  í•™ìŠµ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "í•™ìŠµí•  í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” íŒŒì¼ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” NSMC(Naver Sentiment Movie Corpus) ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œ ë°›ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b7effd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-12 17:40:23--  https://github.com/e9t/nsmc/raw/master/ratings.txt\n",
      "github.com (github.com) í•´ì„ ì¤‘... 20.205.243.166\n",
      "ë‹¤ìŒìœ¼ë¡œ ì—°ê²° ì¤‘: github.com (github.com)|20.205.243.166|:443... ì—°ê²°í–ˆìŠµë‹ˆë‹¤.\n",
      "HTTP ìš”ì²­ì„ ë³´ëƒˆìŠµë‹ˆë‹¤. ì‘ë‹µ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘... 302 Found\n",
      "ìœ„ì¹˜: https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt [ë”°ë¼ê°]\n",
      "--2025-08-12 17:40:23--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\n",
      "raw.githubusercontent.com (raw.githubusercontent.com) í•´ì„ ì¤‘... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "ë‹¤ìŒìœ¼ë¡œ ì—°ê²° ì¤‘: raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... ì—°ê²°í–ˆìŠµë‹ˆë‹¤.\n",
      "HTTP ìš”ì²­ì„ ë³´ëƒˆìŠµë‹ˆë‹¤. ì‘ë‹µ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘... 200 OK\n",
      "ê¸¸ì´: 19515078 (19M) [text/plain]\n",
      "ì €ì¥ ìœ„ì¹˜: `ratings.txt.3'\n",
      "\n",
      "ratings.txt.3       100%[===================>]  18.61M  76.9MB/s    /  0.2s    \n",
      "\n",
      "2025-08-12 17:40:23 (76.9 MB/s) - `ratings.txt.3' ì €ì¥í•¨ [19515078/19515078]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/e9t/nsmc/raw/master/ratings.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facaabde",
   "metadata": {},
   "source": [
    "ë°ì´í„°ì…‹ì„ í™•ì¸í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd94219a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµì— í•„ìš”í•œ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤! ratings.txt\n",
      "ë¦¬ë·° ê°¯ìˆ˜ : 199992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>ì–´ë¦´ë•Œë³´ê³  ì§€ê¸ˆë‹¤ì‹œë´ë„ ì¬ë°Œì–´ìš”ã…‹ã…‹</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>ë””ìì¸ì„ ë°°ìš°ëŠ” í•™ìƒìœ¼ë¡œ, ì™¸êµ­ë””ìì´ë„ˆì™€ ê·¸ë“¤ì´ ì¼êµ° ì „í†µì„ í†µí•´ ë°œì „í•´ê°€ëŠ” ë¬¸í™”ì‚°...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>í´ë¦¬ìŠ¤ìŠ¤í† ë¦¬ ì‹œë¦¬ì¦ˆëŠ” 1ë¶€í„° ë‰´ê¹Œì§€ ë²„ë¦´ê»˜ í•˜ë‚˜ë„ ì—†ìŒ.. ìµœê³ .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>ì™€.. ì—°ê¸°ê°€ ì§„ì§œ ê°œì©”êµ¬ë‚˜.. ì§€ë£¨í• ê±°ë¼ê³  ìƒê°í–ˆëŠ”ë° ëª°ì…í•´ì„œ ë´¤ë‹¤.. ê·¸ë˜ ì´ëŸ°...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>ì•ˆê°œ ììš±í•œ ë°¤í•˜ëŠ˜ì— ë–  ìˆëŠ” ì´ˆìŠ¹ë‹¬ ê°™ì€ ì˜í™”.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                ì–´ë¦´ë•Œë³´ê³  ì§€ê¸ˆë‹¤ì‹œë´ë„ ì¬ë°Œì–´ìš”ã…‹ã…‹      1\n",
       "1   8132799  ë””ìì¸ì„ ë°°ìš°ëŠ” í•™ìƒìœ¼ë¡œ, ì™¸êµ­ë””ìì´ë„ˆì™€ ê·¸ë“¤ì´ ì¼êµ° ì „í†µì„ í†µí•´ ë°œì „í•´ê°€ëŠ” ë¬¸í™”ì‚°...      1\n",
       "2   4655635               í´ë¦¬ìŠ¤ìŠ¤í† ë¦¬ ì‹œë¦¬ì¦ˆëŠ” 1ë¶€í„° ë‰´ê¹Œì§€ ë²„ë¦´ê»˜ í•˜ë‚˜ë„ ì—†ìŒ.. ìµœê³ .      1\n",
       "3   9251303  ì™€.. ì—°ê¸°ê°€ ì§„ì§œ ê°œì©”êµ¬ë‚˜.. ì§€ë£¨í• ê±°ë¼ê³  ìƒê°í–ˆëŠ”ë° ëª°ì…í•´ì„œ ë´¤ë‹¤.. ê·¸ë˜ ì´ëŸ°...      1\n",
       "4  10067386                        ì•ˆê°œ ììš±í•œ ë°¤í•˜ëŠ˜ì— ë–  ìˆëŠ” ì´ˆìŠ¹ë‹¬ ê°™ì€ ì˜í™”.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_list = os.listdir()\n",
    "for file in file_list:\n",
    "    if \"ratings.txt\" == file:\n",
    "        print('í•™ìŠµì— í•„ìš”í•œ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤!', file)\n",
    "        df = pd.read_table( (os.getcwd() + '/' + file), encoding='utf-8') # ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë³´ê¸° í¸í•˜ê²Œ ë°”ê¿”ì¤ì‹œë‹¤!\n",
    "        df = df.dropna(how = 'any') # ë„ê°’ì„ ì—†ì• ì¤ë‹ˆë‹¤!\n",
    "        print('ë¦¬ë·° ê°¯ìˆ˜ :', len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3146be",
   "metadata": {},
   "source": [
    "í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆëŠ” 'document'ì—´ë§Œì„ ê°€ì ¸ì˜¤ê³ \n",
    "\n",
    "í•´ë‹¹ ë°ì´í„°ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0224daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open((os.getcwd() + '/' + 'naver_review.txt'), 'w', encoding='utf8') as f:\n",
    "    # TODO: document ì—´ë§Œ ê°€ì ¸ì™€ì„œ ì €ì¥í•˜ëŠ” ì½”ë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "    # FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252458b8",
   "metadata": {},
   "source": [
    "í•™ìŠµì´ ë˜ì–´ ìˆì§€ ì•Šì€ ë¹ˆ tokenizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” BertWordPieceTokenizerë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "\n",
    "##### íŒŒë¼ë¯¸í„°:\n",
    "- `strip_accents` : ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì•…ì„¼íŠ¸(ì•¡ì„¼íŠ¸)ë¥¼ ì œê±°í• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ì˜µì…˜ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¥¼ í•™ìŠµí• ë•Œì—ëŠ” `False`ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "- `lowercase` : ì˜ì–´ë¥¼ ëª¨ë‘ ì†Œë¬¸ìë¡œ ë°”ê¿‰ë‹ˆë‹¤. `False`ë¡œ ì„¤ì •í•˜ë©´ ì˜ì–´ë¥¼ ëŒ€ë¬¸ìë¡œ ìœ ì§€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d919be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(vocabulary_size=0, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=False, lowercase=False, wordpieces_prefix=##)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "# ë¹ˆ tokenizer ìƒì„± : vocabulary_size = 0 ì¸ ê²ƒì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    lowercase=False,\n",
    "    strip_accents=False,\n",
    ")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e500b",
   "metadata": {},
   "source": [
    "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "#### íŒŒë¼ë¯¸í„° ì„¤ëª…:\n",
    "- `data_file` : ë°ì´í„° ê²½ë¡œë¥¼ ì§€ì •í•´ì¤ë‹ˆë‹¤. list í˜•íƒœë¡œ ì—¬ëŸ¬ê°œì˜ íŒŒì¼ì„ ì§€ì •í•´ì¤„ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "- `vocab_size (default: 30000)` : ë‹¨ì–´ì‚¬ì „ í¬ê¸°ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ë– í•œ ê°’ì´ ê°€ì¥ ì¢‹ë‹¤ëŠ” ê²ƒì€ ì—†ì§€ë§Œ, ê°’ì´ í´ìˆ˜ë¡ ë§ì€ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ë‹´ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- `initial_alphabet` : ê¼­ í¬í•¨ëìœ¼ë©´ í•˜ëŠ” initial alphabetì„ í•™ìŠµ ì „ì— ì¶”ê°€í•´ì¤ë‹ˆë‹¤.\n",
    "    - initialì€ í•™ìŠµí•˜ê¸° ì´ì „ì— ë¯¸ë¦¬ ë‹¨ì–´ë¥¼ vocabì— ë„£ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "    - special tokenë“¤ë„ initialì— vocabì— ì¶”ê°€ë©ë‹ˆë‹¤.\n",
    "- `limit_alphabet (default: 1000)` : initial tokensì˜ ê°¯ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.\n",
    "- `min_frequency (default: 2)` : ìµœì†Œ ë¹ˆë„ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ë§Œì•½ ì–´ë–¤ ë‹¨ì–´ê°€ 1ë²ˆ ë‚˜ì˜¤ë©´ vocabì— ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "- `special_tokens` : íŠ¹ìˆ˜ í† í°ì„ ë„£ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.. BERTì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í† í°ì´ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤.\n",
    "    - `[PAD]` : íŒ¨ë”©ì„ ìœ„í•œ í† í°\n",
    "    - `[UNK]` : OOV ë‹¨ì–´ë¥¼ ìœ„í•œ í† í°\n",
    "    - `[CLS]` : ë¬¸ì¥ì˜ ì‹œì‘ì„ ì•Œë¦¬ê³  ë¶„ë¥˜ ë¬¸ì œì— ì‚¬ìš©ë˜ëŠ” í† í°\n",
    "    - `[SEP]` : ë¬¸ì¥ ì‚¬ì´ì‚¬ì´ë¥¼ êµ¬ë³„í•´ì£¼ëŠ” í† í°\n",
    "    - `[MASK]` : MLM íƒœìŠ¤í¬ë¥¼ ìœ„í•œ ë§ˆìŠ¤í¬ í† í°\n",
    "- `wordpiece_prefix(default: '##')` : sub-wordë¼ëŠ” ê²ƒì„ ì•Œë ¤ì£¼ëŠ” í‘œì‹œì…ë‹ˆë‹¤.\n",
    "    - BERTëŠ” ê¸°ë³¸ì ìœ¼ë¡œ '##'ì„ ì”ë‹ˆë‹¤.\n",
    "    - ì˜ˆë¥¼ ë“¤ì–´, `SS, ##AF, ##Y` ì²˜ëŸ¼ sub-wordë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´ '##'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- `show_progress` : í•™ìŠµ ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82aa578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "vocab size :  30000\n",
      "['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/']\n"
     ]
    }
   ],
   "source": [
    "data_file = 'naver_review.txt'\n",
    "vocab_size = 30000\n",
    "min_frequency = 2\n",
    "initial_alphabet = []\n",
    "limit_alphabet = 6000\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "wordpieces_prefix = \"##\"\n",
    "show_progress=True\n",
    "\n",
    "tokenizer.train(\n",
    "    files = data_file,\n",
    "    vocab_size = vocab_size,\n",
    "    min_frequency = min_frequency,\n",
    "    initial_alphabet = initial_alphabet,\n",
    "    limit_alphabet = limit_alphabet,\n",
    "    special_tokens = special_tokens,\n",
    "    wordpieces_prefix = wordpieces_prefix,\n",
    "    show_progress = True,\n",
    ")\n",
    "\n",
    "vocab = tokenizer.get_vocab()\n",
    "print(\"vocab size : \", len(vocab))\n",
    "print(sorted(vocab, key=lambda x: vocab[x])[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83244f41",
   "metadata": {},
   "source": [
    "### 1.2. í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ í† í° ID ì‹œí€€ìŠ¤ ë°˜í™˜\n",
    "\n",
    "<blockquote>\n",
    "<b>ğŸ§  í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ í† í° ID ì‹œí€€ìŠ¤ ë°˜í™˜</b><br>\n",
    "ëª¨ë¸ì´ í† í°ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ì •ìˆ˜ê°’ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ í† í°ì„ ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "</blockquote>\n",
    "\n",
    "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ í† í°ì„ ID ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26d8b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ±í† í°í™” ê²°ê³¼ : ['I', \"'\", 'm', 'a', 'st', '##ud', '##ent', 'of', 'S', '##S', '##A', '##F', '##Y', '!']\n",
      "ğŸŒ±ì •ìˆ˜ ì¸ì½”ë”© : [45, 11, 81, 69, 15444, 24882, 16071, 10280, 55, 3933, 4150, 4135, 3614, 5]\n",
      "ğŸŒˆë””ì½”ë”© : I ' m a student of SSAFY!\n"
     ]
    }
   ],
   "source": [
    "text = \"I'm a student of SSAFY!\"\n",
    "\n",
    "encoded = tokenizer.encode(text)\n",
    "print('ğŸŒ±í† í°í™” ê²°ê³¼ :',encoded.tokens)\n",
    "print('ğŸŒ±ì •ìˆ˜ ì¸ì½”ë”© :',encoded.ids)\n",
    "print('ğŸŒˆë””ì½”ë”© :',tokenizer.decode(encoded.ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884cec1b",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<b>ğŸ§  í† í¬ë‚˜ì´ì €ë¥¼ ì´ìš©í•œ ëª¨ë¸ ì…ë ¥ ë§Œë“¤ê¸°</b><br>\n",
    "ê·¸ë ‡ë‹¤ë©´ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ìœ„í•´ì„œëŠ” ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ í† í¬ë‚˜ì´ì§•ì„ í•´ì•¼ í• ê¹Œìš”?\n",
    "</blockquote>\n",
    "\n",
    "ìœ„ì— ëŒ€í•œ ë‹µë³€ì€ ì•ìœ¼ë¡œ ì‹¤ìŠµ ì½”ë“œë¥¼ ì§„í–‰í•˜ë©´ì„œ ë‚˜ì˜¤ê¸° ë•Œë¬¸ì— ì´ ì ì„ ìŠì§€ ë§ê³  ê³„ì† ë”°ë¼ê°€ì‹œê¸° ë°”ëë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a906dbd",
   "metadata": {},
   "source": [
    "### 1.3. ì„ë² ë”© ë²¡í„°\n",
    "\n",
    "<blockquote>\n",
    "<b>ğŸ§  í† í° IDì— ë”°ë¼ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ë²¡í„°í™”ê°€ ë ê¹Œìš”?</b><br>\n",
    "í† í° IDì— í•´ë‹¹í•˜ëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "</blockquote>\n",
    "\n",
    "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ íŠ¹ì • í† í° IDì— ë”°ë¥¸ ì„ë² ë”© ë²¡í„°ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì„ë² ë”© ë²¡í„°ëŠ” torchì˜ nn.Embedding ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±ë©ë‹ˆë‹¤. í•´ë‹¹ ì„ë² ë”© ë²¡í„°ëŠ” ëª¨ë‘ ì„ì˜ì˜ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1e9b06",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Embedding.__init__() missing 2 required positional arguments: 'num_embeddings' and 'embedding_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embedding_vector = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Embedding.__init__() missing 2 required positional arguments: 'num_embeddings' and 'embedding_dim'"
     ]
    }
   ],
   "source": [
    "embedding_vector = nn.Embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6473c",
   "metadata": {},
   "source": [
    "ì„ë² ë”© ë²¡í„°ë¥¼ ì´ˆê¸°í™”í•˜ë ¤ê³  í•˜ë‹ˆ ë‹¤ìŒ ë‘ê°€ì§€ íŒŒë¼ë¯¸í„°ë¥¼ ë°˜ë“œì‹œ ë„£ìœ¼ë¼ê³  í•©ë‹ˆë‹¤.\n",
    "\n",
    "1. `num_embeddings`: ì„ë² ë”© ì‚¬ì „ì˜ í¬ê¸° (size of the dictionary of embeddings)\n",
    "2. `embedding_dim`: ê° ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì› (the size of each embedding vector)\n",
    "\n",
    "<blockquote>\n",
    "<b>ğŸ§  num_embeddings </b><br>\n",
    "ì„ë² ë”© ì‚¬ì „ì˜ í¬ê¸°ëŠ” ë¬´ìŠ¨ ì˜ë¯¸ì¼ê¹Œìš”?\n",
    "</blockquote>\n",
    "\n",
    "ì—¬ê¸°ì„œ `num_embeddings`ëŠ” ê³ ìœ í•œ í† í°(ë‹¨ì–´, ë¬¸ì ë“±)ì˜ ì´ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¦‰, ì–´ë–¤ `ì¸ë±ìŠ¤ â†’ ë²¡í„°` ë§¤í•‘ í…Œì´ë¸”ì„ ë§Œë“¤ ê±´ë°, ê·¸ í…Œì´ë¸”ì— ëª‡ ê°œì˜ í•­ëª©ì´ ë“¤ì–´ê°€ì•¼ í•˜ëŠ”ì§€ë¥¼ ì •ì˜í•˜ëŠ” ê°’ì…ë‹ˆë‹¤. tokenizerë¥¼ ë§Œë“¤ë•Œ `vocab_size`ì™€ ë™ì¼í•œ ê°’ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "<blockquote>\n",
    "<b>ğŸ§  embedding_dim </b><br>\n",
    "ê° ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›ì€ ë¬´ìŠ¨ ì˜ë¯¸ì¼ê¹Œìš”?\n",
    "</blockquote>\n",
    "\n",
    "`embedding_dim`ì€ ê° ë‹¨ì–´(ë˜ëŠ” í† í°)ê°€ í‘œí˜„ë˜ëŠ” ë²¡í„°ì˜ ê¸¸ì´ì…ë‹ˆë‹¤. ì¦‰, í•˜ë‚˜ì˜ ë‹¨ì–´ë¥¼ ì–´ë–¤ ìˆ«ì ë²¡í„°ë¡œ ë‚˜íƒ€ë‚¼ ë•Œ ê·¸ ë²¡í„°ê°€ ëª‡ ì°¨ì›ì¸ì§€ ì •í•˜ëŠ” ê°’ì…ë‹ˆë‹¤. ë³´í†µì˜ embeddingì€ `768`, `1024` ë“± 2ì˜ ì œê³±ìˆ˜ ì°¨ì›ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (\"ì–´ë–¤ ê°’ì´ ì •ë‹µì´ë‹¤\" í•˜ëŠ” ê°’ì´ ìˆëŠ” ê±´ ì•„ë‹™ë‹ˆë‹¤.)\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” vocab_sizeì™€ embedding_dimì„ 768ë¡œ ì •ì˜í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9723eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector: Tensor2D[VocabSize, EmbeddingSize] = nn.Embedding(vocab_size, 768)\n",
    "embedding_vector.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a9214e",
   "metadata": {},
   "source": [
    "ê·¸ëŸ¬ë©´ íŠ¹ì • í† í°ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b4c3059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_id: 45\n",
      "input_id ì°¨ì›: torch.Size([1])\n",
      "vector ì°¨ì›: torch.Size([1, 768])\n",
      "vector: tensor([[-5.8641e-01, -1.1327e+00,  2.6612e-02, -3.6936e-01, -4.5574e-01,\n",
      "          1.4395e+00, -2.7049e-01, -2.3921e-02,  4.3165e-01,  6.3602e-01,\n",
      "         -4.0117e-01, -1.0804e+00, -6.4650e-01, -6.8505e-02,  2.4397e-01,\n",
      "         -2.0591e-01, -1.8770e-01,  4.2026e-01,  7.1682e-01, -5.9828e-01,\n",
      "          3.1360e-01,  1.8200e+00,  2.8490e+00,  1.3980e+00,  1.0531e+00,\n",
      "          2.0170e+00,  6.0673e-01, -1.5876e+00,  1.1668e+00, -3.1769e-01,\n",
      "         -5.3360e-01, -4.7004e-01, -9.2409e-01,  1.3773e+00, -1.3743e-01,\n",
      "          4.2839e-02, -4.8446e-01, -9.6651e-01, -1.5018e+00, -4.8411e-01,\n",
      "          1.3622e+00, -1.7072e+00, -7.3317e-01,  2.9438e-01, -1.0314e+00,\n",
      "          1.7281e+00,  1.4170e+00,  1.2014e-01, -1.5709e+00, -3.1901e-01,\n",
      "         -2.0575e-02,  6.4082e-02, -1.9547e-01, -4.9615e-01,  4.1448e-01,\n",
      "         -2.1306e-01, -8.5294e-02,  5.7862e-01,  9.8439e-02,  7.3975e-01,\n",
      "          2.4581e-02,  9.2886e-02, -3.3140e-01, -1.3073e-01,  1.6888e+00,\n",
      "         -1.6246e-01,  3.6534e-01,  1.8052e+00, -5.4247e-01,  1.1382e+00,\n",
      "         -1.1691e-02, -6.5054e-01, -2.9788e+00, -1.7490e+00, -5.2741e-01,\n",
      "         -8.1005e-01,  3.9198e-01,  1.4487e-01,  4.4438e-01, -9.0061e-01,\n",
      "          2.6250e-01, -2.9051e-01,  2.2310e-01, -1.2519e+00,  1.2721e+00,\n",
      "          6.2651e-01,  1.5596e+00, -8.3331e-02, -4.1976e-01,  1.7190e+00,\n",
      "         -8.3126e-01,  1.6253e+00, -2.3224e-01,  8.6379e-01,  6.8156e-01,\n",
      "         -1.7146e+00, -1.4344e-01,  5.6220e-02, -1.8790e+00, -9.5746e-01,\n",
      "          6.4773e-01,  1.7119e-01, -5.1799e-01, -2.9002e-01, -1.4499e+00,\n",
      "         -2.2011e+00, -1.9358e+00,  1.7292e+00,  3.2779e-01,  9.1354e-01,\n",
      "         -1.8337e-01, -1.0150e+00,  6.1067e-02, -1.6252e-01, -1.8904e-01,\n",
      "         -3.1064e-01,  6.4264e-01,  2.4448e+00, -8.2296e-01,  2.3123e-01,\n",
      "          5.2089e-01,  2.2307e-01,  8.9294e-01, -3.4659e-01, -2.2180e+00,\n",
      "         -2.9681e-01,  1.9733e-01,  1.0184e+00, -5.8794e-01,  1.0451e+00,\n",
      "          1.6000e+00,  1.0269e-01, -6.3995e-01,  2.5967e-01, -1.2352e-01,\n",
      "          6.0335e-01, -1.0959e-01,  1.3712e+00,  2.6667e-01, -1.0211e+00,\n",
      "          2.7895e-01, -1.2074e+00, -9.0694e-01,  8.2587e-01,  2.1134e-01,\n",
      "          4.1955e-01, -2.6536e-01, -1.1998e+00,  5.6761e-01,  1.3631e+00,\n",
      "         -1.1470e+00,  2.3841e-01, -1.0672e+00,  1.2854e+00, -2.5034e+00,\n",
      "          1.0756e+00,  7.8051e-02, -1.1610e+00,  2.3808e+00,  5.8393e-03,\n",
      "          1.2712e+00,  6.9454e-01, -2.0363e+00,  4.2008e-01,  1.4959e+00,\n",
      "         -2.6621e+00, -1.1025e+00, -8.7692e-01,  2.7085e-01, -3.6835e-01,\n",
      "         -4.5597e-01,  1.6099e-01,  2.2385e+00,  7.7596e-01,  6.9936e-01,\n",
      "          1.2859e-02, -1.0188e+00,  2.0262e-01,  1.0505e-01, -5.3979e-01,\n",
      "         -1.1471e+00,  1.0325e+00,  2.2522e-01,  1.7242e-01,  8.4644e-01,\n",
      "         -3.9182e-01, -1.3194e+00,  1.9120e+00,  1.1990e+00, -7.1338e-01,\n",
      "         -2.9062e-01, -1.9692e+00, -1.2352e+00,  3.4469e-01,  3.7266e-01,\n",
      "          7.4043e-03,  1.7676e-01,  4.4155e-01, -2.8602e-01,  1.1501e+00,\n",
      "         -4.9747e-01, -2.1877e+00,  1.2597e+00, -4.6811e-01, -1.9778e+00,\n",
      "          9.2266e-02,  8.3967e-01, -1.2875e+00, -4.5443e-01,  8.2618e-01,\n",
      "          1.3657e+00, -1.6183e-01,  2.7951e+00,  5.9410e-01, -8.6167e-01,\n",
      "         -2.4812e+00,  5.2129e-01,  1.0565e+00,  8.2845e-01, -3.9922e-01,\n",
      "          1.6755e+00,  2.2296e+00,  1.4605e+00, -1.3790e+00,  8.9979e-02,\n",
      "         -8.4355e-01, -6.2137e-01,  8.8655e-01, -7.5264e-01,  4.5718e-02,\n",
      "         -8.8061e-01, -1.3311e+00,  2.6024e+00, -8.8568e-02,  3.6131e-01,\n",
      "         -9.6495e-01,  2.5996e-01, -4.8475e-01, -1.1931e+00, -3.5962e-03,\n",
      "          4.5652e-01,  1.1003e+00,  6.0825e-01,  5.0255e-01,  6.4847e-02,\n",
      "         -2.0972e-01, -8.1905e-01,  6.3713e-01,  5.5610e-01, -3.7969e-01,\n",
      "         -8.2476e-01,  3.0568e-01,  1.3790e+00,  1.0315e+00, -1.1049e+00,\n",
      "         -1.2539e+00,  7.8217e-01,  4.2802e-01,  5.2194e-01, -4.2326e-01,\n",
      "          6.9081e-01, -1.1530e+00,  1.0535e+00,  8.4309e-01, -1.5127e+00,\n",
      "          1.5953e+00,  1.5544e+00, -3.3269e-01,  1.8270e+00,  2.3450e-01,\n",
      "         -2.6720e-01, -4.8002e-01, -7.2525e-01, -6.9045e-02,  1.8810e-02,\n",
      "          1.4364e-01, -2.2373e+00,  4.0876e-01, -3.7807e-02, -8.5370e-01,\n",
      "         -1.4437e+00, -1.5806e+00,  1.6538e+00,  6.1369e-01,  5.1194e-01,\n",
      "         -1.4412e+00,  6.9254e-01,  1.6215e+00, -8.9781e-01, -2.6808e-01,\n",
      "          6.8007e-01, -2.5736e+00,  3.0228e-01, -2.1020e-01,  4.0738e-01,\n",
      "         -1.2795e+00, -2.1194e+00, -2.3627e-01,  6.4997e-01,  2.0307e-01,\n",
      "         -4.0661e-01, -9.2588e-01, -6.6186e-01, -9.7114e-01, -1.2413e+00,\n",
      "          1.6439e-01,  1.1636e+00,  3.6198e-01, -1.1532e+00, -1.0988e+00,\n",
      "          5.3209e-01, -8.9032e-01,  1.1218e+00,  5.7064e-01,  7.5646e-01,\n",
      "          1.3166e+00,  1.2176e+00, -5.0478e-01, -6.4268e-01,  2.3216e+00,\n",
      "          1.1027e+00,  2.3127e-01,  4.6957e-01, -6.8633e-01, -1.4759e+00,\n",
      "          1.4607e-01, -8.5485e-01,  5.1082e-01,  2.7225e-01, -1.0504e+00,\n",
      "         -1.8880e+00,  8.0767e-01, -1.0015e+00, -2.9965e-01, -6.4340e-01,\n",
      "         -1.1795e+00,  1.2514e+00, -1.1169e+00, -6.2890e-03, -2.4045e+00,\n",
      "         -1.5852e-01,  7.9345e-01, -2.9591e-01,  8.2604e-01, -3.5559e-01,\n",
      "          1.7587e-01,  1.5028e-01, -2.7314e-01,  3.9683e-02, -1.1727e+00,\n",
      "         -1.7857e+00, -1.6997e+00,  9.1090e-01,  6.2496e-01,  7.2536e-02,\n",
      "         -2.5993e-01, -7.4421e-01, -1.4108e+00,  1.1926e-01,  9.8203e-01,\n",
      "          5.4706e-01,  1.0072e-01, -7.9624e-02,  7.1058e-02,  1.7737e-01,\n",
      "          7.5613e-01, -1.2531e+00,  6.6835e-01, -1.0337e+00, -9.1633e-01,\n",
      "          4.8913e-01, -4.7103e-01, -4.2296e-01, -8.8159e-01, -1.6258e+00,\n",
      "          8.6559e-01,  8.9447e-01,  1.0847e+00,  2.9223e-01,  1.3801e+00,\n",
      "          5.5510e-01,  2.3797e-01,  1.6000e-01, -2.7714e-01, -1.3358e+00,\n",
      "         -1.5762e-01, -1.0363e+00,  9.8573e-01, -1.1911e+00,  2.4253e-01,\n",
      "          5.4839e-01,  1.3786e+00,  1.5118e+00,  2.5880e-01,  1.1013e+00,\n",
      "          1.4151e+00, -1.2057e-01,  1.3439e-01, -1.5628e+00, -6.1287e-01,\n",
      "         -1.1348e+00, -9.6102e-01,  1.7011e+00,  5.0617e-01, -1.9768e+00,\n",
      "         -5.6951e-01,  1.5390e+00,  6.3183e-02, -1.6705e+00,  1.4659e+00,\n",
      "          1.1269e+00, -3.0730e+00, -1.1650e+00,  1.1070e+00,  2.4070e-01,\n",
      "          2.7651e-01, -1.2080e+00,  4.8507e-01,  7.9149e-02,  5.4360e-01,\n",
      "         -8.3520e-01,  9.3864e-01, -8.5778e-01,  3.6294e-01,  1.0618e+00,\n",
      "          1.3808e-01, -3.9061e-02, -3.5348e-01,  2.1225e+00, -7.2674e-01,\n",
      "         -1.7458e+00,  1.0003e+00,  2.8215e-02,  1.1499e+00,  4.2818e-01,\n",
      "          1.5518e+00, -8.6611e-01,  1.4710e+00, -8.2705e-01,  9.8005e-02,\n",
      "          2.6920e+00,  1.3048e+00,  6.0844e-01, -1.2385e+00,  4.6886e-01,\n",
      "         -8.6682e-01,  1.0413e+00, -2.7178e-01,  1.4223e+00,  2.9257e+00,\n",
      "          9.2931e-02,  5.7789e-01, -1.5264e+00,  3.8429e-01,  3.2746e-01,\n",
      "         -1.1850e+00,  1.0487e+00, -1.0260e-01,  5.1305e-01, -4.3763e-01,\n",
      "         -1.1442e+00,  1.6211e-01,  1.0189e-01, -8.6003e-01,  3.7350e-01,\n",
      "         -2.0934e+00,  9.4786e-01,  8.0349e-01,  9.0875e-02, -7.2433e-01,\n",
      "          8.9107e-01,  2.8971e-01,  1.4685e+00, -9.0758e-01,  1.0190e+00,\n",
      "         -1.1583e+00, -1.5949e+00, -2.5171e-01,  2.0537e-01, -1.7279e+00,\n",
      "          2.3990e-01, -2.2937e+00,  6.8148e-01,  1.5945e+00,  4.0917e-01,\n",
      "         -7.5195e-01,  1.1046e-01, -1.5076e+00, -8.0238e-01,  2.2897e-01,\n",
      "          6.2368e-01, -3.0776e-01, -1.5446e-01,  9.0203e-01,  2.1589e+00,\n",
      "          1.4359e-02, -2.0427e-01,  4.5405e-01,  1.6242e+00,  2.4179e+00,\n",
      "          1.9296e-02, -1.0937e+00, -4.3272e-01, -8.0123e-01,  1.6898e-01,\n",
      "         -7.9126e-01, -3.3747e-01, -2.6263e-01,  6.3985e-01,  1.9795e+00,\n",
      "          5.0256e-01,  4.2781e-01,  9.2407e-01, -1.1289e+00,  1.6008e+00,\n",
      "          2.7487e-01,  2.4097e-01,  6.6713e-01, -5.3765e-01, -3.8973e-01,\n",
      "          5.5697e-01,  5.1861e-02, -1.0619e+00, -1.9407e+00, -1.1581e+00,\n",
      "          3.4482e-01, -7.0241e-01,  1.4376e+00, -1.1725e+00, -3.8754e-01,\n",
      "          6.0148e-01, -4.2554e-01, -1.6213e-01,  6.2803e-02,  5.8063e-01,\n",
      "         -3.4327e-01, -4.5692e-01,  9.6038e-01,  6.9764e-01,  1.0929e+00,\n",
      "          1.7693e+00, -3.1421e-02, -1.0884e+00, -1.0127e-01, -1.9810e-01,\n",
      "          4.4012e-02, -1.2764e+00, -1.0442e+00,  4.5751e-01,  3.7497e-01,\n",
      "         -8.9870e-01, -8.6049e-03,  1.6212e+00,  2.1729e-01, -1.3368e+00,\n",
      "         -4.6538e-04,  5.7354e-01, -1.4653e+00,  1.1711e+00,  2.9986e-01,\n",
      "          2.3952e-01, -6.4066e-01,  3.2257e-01, -1.0702e+00, -4.5255e-01,\n",
      "          8.4570e-01,  8.7082e-01, -1.2804e+00, -8.0807e-01, -1.0393e+00,\n",
      "          1.8883e-01,  2.9374e-01,  1.8074e-02,  1.1724e+00, -5.2455e-01,\n",
      "         -4.1127e-01,  6.3151e-01, -3.2293e-01,  1.1213e+00,  8.8539e-01,\n",
      "         -7.4528e-01,  2.5474e+00,  4.3508e-01,  1.5564e-01, -2.8813e-01,\n",
      "         -1.4950e+00,  1.9958e+00, -4.4929e-01,  5.7363e-01,  1.3688e+00,\n",
      "          9.8464e-01, -1.5622e+00,  2.9645e-01,  7.9629e-02, -1.0188e+00,\n",
      "         -2.8821e-01,  6.5786e-01, -9.4752e-01, -6.8457e-02,  5.4615e-01,\n",
      "          3.1922e-01, -9.3858e-01,  2.0790e+00,  2.0641e-01,  1.3692e+00,\n",
      "          3.6679e-01,  1.2206e-01,  3.4521e-01,  2.1476e-01,  9.4113e-01,\n",
      "          9.7986e-01, -1.2927e+00, -4.6423e-01, -2.4949e-01,  1.5714e+00,\n",
      "          6.6313e-01,  4.8623e-01,  7.1229e-02, -1.1668e-01,  1.0935e+00,\n",
      "         -4.1720e-01,  1.2234e-01,  2.5845e-01, -5.0578e-01,  1.6090e+00,\n",
      "          4.8092e-02,  2.7948e-01,  4.5103e-01, -5.2214e-01, -1.2607e+00,\n",
      "         -5.7107e-01, -5.7751e-01,  6.6488e-01, -1.7756e+00,  6.5838e-01,\n",
      "         -2.7618e-01, -1.5014e+00,  5.9242e-01,  1.7892e+00,  1.5430e+00,\n",
      "          2.9727e-01,  1.8970e+00,  2.3541e-01,  7.3836e-01, -2.1829e-01,\n",
      "         -5.6520e-01, -5.2170e-01, -2.8841e-01,  1.7133e+00,  1.3969e-01,\n",
      "         -4.4374e-01, -1.5180e+00,  5.8020e-01, -1.4620e-01, -1.8151e+00,\n",
      "          1.8509e+00, -5.7693e-01,  6.2626e-01, -7.9069e-01, -1.7662e+00,\n",
      "         -7.7322e-01, -1.0780e-01,  8.9673e-01,  2.0367e+00,  6.2815e-01,\n",
      "         -5.8681e-01, -1.0963e+00,  5.1416e-01, -1.6618e+00, -2.3677e-01,\n",
      "          5.0208e-01, -3.8207e-01,  4.7563e-01, -7.4501e-01, -1.4155e-01,\n",
      "         -2.1625e-01, -1.9711e+00, -1.2997e+00,  6.5497e-01, -2.1389e-01,\n",
      "         -1.5022e-01, -4.7207e-01,  1.0380e+00,  1.0139e+00, -1.5492e+00,\n",
      "         -9.2274e-01, -3.6818e-03, -1.9299e+00, -3.1747e-01,  4.3391e-01,\n",
      "          6.2427e-01,  9.4415e-01, -1.2236e+00, -1.2878e-01,  3.8714e-01,\n",
      "          9.4548e-01, -8.0918e-01, -2.0064e+00,  4.8596e-02, -9.9246e-01,\n",
      "          4.3346e-01,  1.9962e-01, -1.0281e+00,  1.2949e+00, -9.7883e-01,\n",
      "          7.2204e-01,  1.6217e-01,  1.1873e+00, -1.6302e+00, -1.6191e-01,\n",
      "          7.4264e-01,  1.2234e-01,  5.3141e-02, -1.7858e+00,  9.8436e-02,\n",
      "         -5.4184e-01,  4.1263e-01,  8.8509e-01, -3.8275e-01, -5.5372e-01,\n",
      "         -1.0093e+00, -1.8745e+00, -3.1292e-02, -6.5305e-01,  9.3340e-01,\n",
      "         -8.9972e-01,  1.0360e+00, -8.8613e-01, -3.8863e-01,  2.2449e-01,\n",
      "         -1.0740e+00,  5.8647e-01, -8.3409e-01, -2.4781e+00, -1.6360e+00,\n",
      "         -1.2667e+00,  1.0647e+00,  6.0862e-01,  1.0411e+00,  4.9001e-01,\n",
      "         -5.6568e-01, -7.7290e-02,  1.6889e+00, -5.3592e-01,  3.0126e-01,\n",
      "         -9.3709e-01, -1.0054e+00,  6.8849e-02,  6.9186e-01, -1.2959e+00,\n",
      "          8.7209e-01,  2.7381e-01,  1.6178e+00,  3.3304e-01,  2.3623e+00,\n",
      "          4.5610e-01, -7.9843e-02, -2.8436e-01, -1.5437e+00, -1.1984e+00,\n",
      "         -7.8466e-01,  1.1022e+00,  1.5757e-01, -1.2095e+00,  2.2163e-01,\n",
      "          6.4150e-01,  1.0414e+00,  8.6908e-01]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "token_id = tokenizer.token_to_id(\"I\")\n",
    "print(\"token_id:\", token_id)\n",
    "input_id = torch.tensor([token_id], dtype=torch.long)\n",
    "print(\"input_id ì°¨ì›:\", input_id.shape)\n",
    "\n",
    "vector = embedding_vector(input_id)\n",
    "print(\"vector ì°¨ì›:\", vector.shape)\n",
    "print(\"vector:\", vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f47d8d6",
   "metadata": {},
   "source": [
    "# 2. RNN/LSTM\n",
    "\n",
    "- í•™ìŠµ ëª©í‘œ\n",
    "  1. RNN/LSTMì„ ì´ìš©í•˜ì—¬ ë¬¸ì¥ ì „ì²´ì˜ ì •ë³´ë¥¼ ì••ì¶•í•œ ë¬¸ë§¥ ë²¡í„°ì— ëŒ€í•œ ì´í•´ë¥¼ í•  ìˆ˜ ìˆë‹¤.\n",
    "  2. Encoder Decoder êµ¬ì¡°ë¥¼ í†µí•´ ë¬¸ë§¥ ë²¡í„°ë¥¼ ì´ìš©í•˜ì—¬ íŠ¹ì • taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.\n",
    "- í•™ìŠµ ê°œë…\n",
    "  1. RNN/LSTM\n",
    "  2. Encoder/Decoder\n",
    "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
    "  1. ê°„ë‹¨í•œ RNN/LSTMì„ êµ¬í˜„í•œë‹¤.\n",
    "  2. ë²ˆì—­ taskì™€ ê´€ë ¨ëœ encoder decoder êµ¬ì¡°ë¥¼ êµ¬í˜„í•œë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cfb8ca",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<b>ğŸ§  Recurrent Neural Network(RNN)ì´ë€? </b><br>\n",
    "ìˆœì°¨ì (Sequential) ì´ì „ì˜ ì •ë³´ë¥¼ ê¸°ì–µí•˜ì—¬ í˜„ì¬ì˜ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "</blockquote>\n",
    "\n",
    "RNNì´ ê°–ëŠ” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ì…ë ¥ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "- RNNì€ ê°™ì€ ê°€ì¤‘ì¹˜ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- ì¬ê·€ì ì¸ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4dfc5c",
   "metadata": {},
   "source": [
    "ê·¸ëŸ¬ë©´ ì´ì œë¶€í„° ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ RNNì— ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì„œ ì¶œë ¥ì¸µì˜ ê²°ê³¼ê°’ì„ ë°›ì•„ë´…ì‹œë‹¤!\n",
    "\n",
    "í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ìœ„í•´ì„œëŠ” ìœ„ì—ì„œ ë³´ì•˜ë“¯, ì›Œë“œ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ì›Œë“œ ì„ë² ë”©ì„ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b720ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›Œë“œ ì„ë² ë”© ì°¨ì› : torch.Size([30000, 768])\n"
     ]
    }
   ],
   "source": [
    "word_embeddings: Tensor2D[VocabSize, EmbeddingSize] = nn.Embedding(vocab_size, 768)\n",
    "print(\"ì›Œë“œ ì„ë² ë”© ì°¨ì› :\", word_embeddings.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9be639",
   "metadata": {},
   "source": [
    "ì›Œë“œ ì„ë² ë”© ì°¨ì›ì— ë§ê²Œ RNNì„ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6cf6ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_0ì˜ ì°¨ì› : torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "input_size: int = word_embeddings.weight.size()[1] # RNNì˜ input sizeëŠ” ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì›ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "hidden_size: int = 1024  # RNNì˜ hidden size\n",
    "num_layers: int = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
    "bidirectional: bool = False  # ë‹¨ë°©í–¥ RNN\n",
    "\n",
    "rnn = nn.RNN(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=bidirectional\n",
    ")\n",
    "\n",
    "# ì´ˆê¸° hidden state ì´ˆê¸°í™”\n",
    "\n",
    "hidden_state_shape: int = (num_layers * (2 if bidirectional else 1), hidden_size)\n",
    "\n",
    "h_0: Tensor2D[Sequence, HiddenStates] = torch.zeros(hidden_state_shape)  # (num_layers * num_dirs, hidden_size)\n",
    "print(\"h_0ì˜ ì°¨ì› :\",h_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4f18e",
   "metadata": {},
   "source": [
    "ì…ë ¥ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í°í™”í•œ í›„, idsë§Œ êº¼ëƒ…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf10c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6227, 7125, 3279, 9046,   18])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text: str = \"ë‚˜ëŠ” í•™êµì— ê°„ë‹¤.\"\n",
    "\n",
    "# í† í°í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "encoded = tokenizer.encode(text)\n",
    "# í† í°ì˜ idsë§Œ êº¼ëƒ…ë‹ˆë‹¤.\n",
    "input_ids: List[int] = encoded.ids\n",
    "\n",
    "# í…ì„œí™”ë¥¼ í•©ë‹ˆë‹¤.\n",
    "input_ids: Tensor1D[Sequence] = torch.tensor(input_ids, dtype=torch.long)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13935ca0",
   "metadata": {},
   "source": [
    "ë³€í™˜ëœ input_idsë¥¼ ì›Œë“œ ì„ë² ë”©ìœ¼ë¡œ ë„£ê³ \n",
    "ì›Œë“œ ì„ë² ë”©ì„ RNNì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ ë‘ outputì„ ì–»ìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. `hidden_states`: ê° time stepì— í•´ë‹¹í•˜ëŠ” hidden stateë“¤ì˜ ë¬¶ìŒ.\n",
    "2. `h_n`: ëª¨ë“  sequenceë¥¼ ê±°ì¹˜ê³  ë‚˜ì˜¨ ë§ˆì§€ë§‰ hidden state(`last hidden state`). hidden_statesì˜ ë§ˆì§€ë§‰ê³¼ ë™ì¼."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d65561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›Œë“œ ì„ë² ë”© ì°¨ì› :  torch.Size([5, 768])\n",
      "hidden_states ì°¨ì› :  torch.Size([5, 1024])\n",
      "h_n ì°¨ì› :  torch.Size([1, 1024])\n",
      "hidden_statesì˜ ë§ˆì§€ë§‰ê³¼ h_nì´ ê°™ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "input_embeds: Tensor2D[Sequence, EmbeddingSize] = word_embeddings(input_ids)\n",
    "print(\"ì›Œë“œ ì„ë² ë”© ì°¨ì› : \", input_embeds.shape)  # (vocab_size, embedding_dim)\n",
    "outputs = rnn(input_embeds, h_0)\n",
    "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
    "h_n: Tensor2D[Layers, HiddenStates] = outputs[1]\n",
    "\n",
    "# sequence_length: input_tokenì˜ ê¸¸ì´(length), hidden size: hidden state ì°¨ì› ìˆ˜, num_layers: layer ê°œìˆ˜, num_dirs: ë°©í–¥ì˜ ê°œìˆ˜\n",
    "print(\"hidden_states ì°¨ì› : \", hidden_states.shape)  # (sequence_length, d_h)\n",
    "print(\"h_n ì°¨ì› : \", h_n.shape)  # (num_layers * num_dirs, d_h) = (1, d_h)\n",
    "\n",
    "if torch.equal(hidden_states[-1].unsqueeze(0), h_n):\n",
    "    print(\"hidden_statesì˜ ë§ˆì§€ë§‰ê³¼ h_nì´ ê°™ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc103e",
   "metadata": {},
   "source": [
    "ê·¸ëŸ¬ë©´ ì´ëŸ¬í•œ ì€ë‹‰ ìƒíƒœ(hidden state)ë¥¼ ì–»ì–´ì„œ ì–´ë– í•œ ì‘ì—…ì„ í•  ìˆ˜ ìˆì„ê¹Œìš”?\n",
    "\n",
    "<blockquote>\n",
    "<b>ğŸ§  ì€ë‹‰ ìƒíƒœ(hidden state)ëŠ” ë¬¸ì¥ì˜ ì •ë³´ë“¤ì„ ì••ì¶•ì ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.</b><br>\n",
    "RNN layerë¥¼ í†µê³¼í•˜ë©´ì„œ ë¬¸ì¥ ì „ì²´ì˜ ì •ë³´ë¥¼ ì••ì¶•í•˜ê²Œ ë˜ê³  ì´ëŸ¬í•œ ì •ë³´ë“¤ì€ hidden stateì— ë‹´ê¸°ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ hidden stateëŠ” ë¬¸ë§¥ ë²¡í„°(context vector)ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "</blockquote>\n",
    "\n",
    "ë¬¸ë§¥ ë²¡í„°(context vector)ëŠ” ì…ë ¥ ë¬¸ì¥ì˜ ì •ë³´ë“¤ì„ ë²¡í„°ìƒì— ì••ì¶•í•˜ì—¬ ì €ì¥í•œ ê²ƒìœ¼ë¡œ, ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” ë²ˆì—­(translation) taskë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ hidden stateë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë²ˆì—­ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” last hidden stateë¥¼ ë‹¤ì‹œ ì €í¬ì˜ ì…ë ¥ ë°ì´í„°ì™€ ìœ ì‚¬í•œ í˜•íƒœì¸ í…ìŠ¤íŠ¸(í† í°) idë¡œ ë³€í™˜í•˜ëŠ” layerê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¥¼ ì €í¬ëŠ” Decoderë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n",
    "\n",
    "![image](https://raw.githubusercontent.com/Ssunbell/TIL/refs/heads/master/assets/Seq2SeqRNN.png)\n",
    "\n",
    "ê·¸ëŸ¬ë©´ ì•„ë˜ì—ì„œ Encoderì™€ Decoderë¥¼ ì—°ê²°í•˜ì—¬ ë²ˆì—­ì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì € ì¸ì½”ë”ë¥¼ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ êµ¬í˜„í•œ rnnì„ ê·¸ëŒ€ë¡œ ì´ìš©í•˜ì—¬ í´ë˜ìŠ¤í™”ë¥¼ ì§„í–‰í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ff084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states ì°¨ì› :  torch.Size([5, 1024])\n",
      "h_n ì°¨ì› :  torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# ì¸ì½”ë” ëª¨ë¸ì€ RNNì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” ì¶”ìƒí™” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
    "class Encoder(nn.Module, ABC):\n",
    "    def __init__(self: \"Encoder\") -> None:\n",
    "        super().__init__()\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self: \"Encoder\", input_ids: torch.Tensor) -> torch.Tensor:\n",
    "        # forwardì—ì„œ ì‹¤ì œë¡œ ì¸ì½”ë”©ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë ˆì´ì–´ë¥¼ ìŒ“ìŠµë‹ˆë‹¤.\n",
    "        pass\n",
    "\n",
    "class RNNEncoder(Encoder):\n",
    "    def __init__(\n",
    "        self: \"RNNEncoder\",\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        bidirectional: bool,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # word embedding layer\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # rnn layer\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "    \n",
    "    def forward(\n",
    "        self: \"RNNEncoder\",\n",
    "        input_ids: Tensor1D[Sequence]\n",
    "    ) -> Tuple[Tensor2D[Sequence, HiddenStates], Tensor2D[Layers, HiddenStates]]:\n",
    "        \"\"\"ì…ë ¥ í† í°ì„ ì›Œë“œ ì„ë² ë”©ì„ í†µí•´ ì„ë² ë”© ë³€í™˜ì„ í•©ë‹ˆë‹¤.\"\"\"\n",
    "        input_embeds = self.word_embeddings(input_ids)\n",
    "        \n",
    "        \"\"\"RNNì„ í†µí•´ ì…ë ¥ ì„ë² ë”©ì„ ë¬¸ë§¥ ë²¡í„°(context vector)í™” í•©ë‹ˆë‹¤.\"\"\"\n",
    "        outputs = self.rnn(input_embeds)\n",
    "        # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
    "        # hidden_states: Tensor2D[Sequence, HiddenStates] = FIXME\n",
    "        # h_n: Tensor2D[Layers, HiddenStates] = FIXME\n",
    "        \n",
    "        return hidden_states, h_n\n",
    "\n",
    "vocab_size = 30000\n",
    "embedding_dim = 768\n",
    "hidden_size = 1024  # RNNì˜ hidden size\n",
    "num_layers = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
    "bidirectional = False  # ë‹¨ë°©í–¥ RNN\n",
    "\n",
    "rnn_encoder = RNNEncoder(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=bidirectional\n",
    ")\n",
    "\n",
    "outputs = rnn_encoder(input_ids)\n",
    "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
    "h_n: Tensor2D[Layers, HiddenStates] = outputs[1]\n",
    "print(\"hidden_states ì°¨ì› : \", hidden_states.shape)  # (L, B, d_h)\n",
    "print(\"h_n ì°¨ì› : \", h_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, B, d_h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b15bc9",
   "metadata": {},
   "source": [
    "ë‹¤ìŒ ë””ì½”ë” ë¶€ë¶„ì„ êµ¬í˜„í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3b846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•©ì›ƒê³ ì½ìŠ¤í„°ëª¨ë¡œ ë¶€íƒí•©ë‹ˆë‹¤ ìŠˆí¼ì•¡ì…˜ ì§¯ ì•„íŒŒ ê³µê°ë˜ëŠ”\n"
     ]
    }
   ],
   "source": [
    "# ë””ì½”ë” ëª¨ë¸ ë˜í•œ RNNì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "class Decoder(nn.Module, ABC):\n",
    "    def __init__(self: \"Decoder\") -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, input_ids: torch.Tensor, init_hidden_state: torch.Tensor) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "class RNNDecoder(Decoder):\n",
    "    def __init__(\n",
    "        self: \"RNNDecoder\",\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        bidirectional: bool,\n",
    "        start_token_id: int,\n",
    "        end_token_id: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.start_token_id = start_token_id\n",
    "        self.end_token_id = end_token_id\n",
    "        # word embedding layer\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # rnn layer\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "        # fully connected layer\n",
    "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self: \"RNNDecoder\",\n",
    "        init_hidden_state: Tensor2D[Layers, HiddenStates],\n",
    "        max_len: int = 10\n",
    "    ) -> Tuple[Tensor2D[MaxLength, VocabSize], List[int]]:\n",
    "        logits: List[Tensor1D[VocabSize]] = []\n",
    "        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n",
    "        output_token_ids: List[int] = [input_token.item()] # tensorì—ì„œ item()ì„ ì‚¬ìš©í•˜ì—¬ intë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "        h_n = init_hidden_state # h_nì€ encoderì˜ h_0ì™€ ë™ì¼í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            if input_token == self.end_token_id:\n",
    "                # ë¬¸ì¥ì˜ ì¢…ë£Œë¥¼ ì˜ë¯¸í•˜ëŠ” special token([SEP])ì´ ë‚˜ì™”ë‹¤ë©´ ì¶”ë¡ (ìƒì„±)ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "                break\n",
    "\n",
    "            \"\"\"ì§ì „ í† í°ë§Œ ì…ë ¥ìœ¼ë¡œ ë„£ê³  ìƒì„±í•œ context vectorëŠ” logitsì— ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "            # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
    "            # embedded: Tensor2D[Token, EmbeddingSize] = FIXME\n",
    "            # outputs = FIXME\n",
    "            # h_n: Tensor2D[Layers, HiddenStates] = FIXME\n",
    "            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # ì—¬ê¸°ì„œëŠ” layer ê°¯ìˆ˜ê°€ 1ì´ê³ , bidirectionalì´ Falseì´ë¯€ë¡œ squeezeë¥¼ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤. (ì›ë˜ëŠ” torch.catìœ¼ë¡œ h_nì„ í•©ì¹˜ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.)\n",
    "\n",
    "            \"\"\"fully connected layerë¥¼ í†µí•´ [VocabSize]ì˜ logitì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "            logit: Tensor1D[VocabSize] = self.fully_connected_layer(concat_h_n)\n",
    "            logits.append(logit)\n",
    "\n",
    "            \"\"\"logit ë‚´ì—ì„œ ê°€ì¥ ë†’ì€ ì ìˆ˜ê°’ì„ ê°€ì§„ í† í°ì„ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
    "            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
    "            output_token_ids.append(input_token.item())\n",
    "        \n",
    "        \"\"\"ë¦¬ìŠ¤íŠ¸ì˜ logitsë¥¼ torchì˜ Tensorë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\"\"\"\n",
    "        logits = torch.stack(logits, dim=0)  # [max_len, vocab_size]\n",
    "\n",
    "        return logits, output_token_ids\n",
    "\n",
    "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
    "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
    "\n",
    "vocab_size: int = 30000\n",
    "embedding_dim: int = 768\n",
    "hidden_size: int = 1024  # RNNì˜ hidden size\n",
    "num_layers: int = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
    "bidirectional: bool = False  # ë‹¨ë°©í–¥ RNN\n",
    "\n",
    "rnn_decoder = RNNDecoder(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=bidirectional,\n",
    "    start_token_id=start_token_id,\n",
    "    end_token_id=end_token_id,\n",
    ")\n",
    "logits, output_token_ids = rnn_decoder(h_n)\n",
    "output_texts = tokenizer.decode(output_token_ids)\n",
    "print(output_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43d683",
   "metadata": {},
   "source": [
    "ì´ì œ êµ¬í˜„í•œ encoderì™€ decoderë¥¼ ì—°ê²°í•˜ì—¬ seq2seq ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55b85dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•©ì›ƒê³ ì½ìŠ¤í„°ëª¨ë¡œ ë¶€íƒí•©ë‹ˆë‹¤ ìŠˆí¼ì•¡ì…˜ ì§¯ ì•„íŒŒ ê³µê°ë˜ëŠ”\n"
     ]
    }
   ],
   "source": [
    "class RNNSeq2Seq(nn.Module):\n",
    "    def __init__(self: \"RNNSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self: \"RNNSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
    "        hidden_states, context_vector = self.encoder(input_ids) # encoderì—ì„œ ìƒì„±í•œ context_vector(h_n)ì„ decoder layerë¡œ ì „ë‹¬\n",
    "        logits, output_tokens = self.decoder(context_vector)\n",
    "\n",
    "        return logits, output_tokens\n",
    "\n",
    "seq2seq = RNNSeq2Seq(rnn_encoder, rnn_decoder)\n",
    "logits, output_tokens = seq2seq(input_ids)\n",
    "output_token_ids = logits.argmax(dim=-1)\n",
    "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
    "print(output_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7487e",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<b>ğŸ¤” ê²°ê³¼ê°’ì´ ì´ìƒí•´ìš”</b><br>\n",
    "ë°ì´í„°ë¡œ ì¶©ë¶„íˆ í•™ìŠµì„ í•˜ì§€ ì•Šì•„ì„œ ê·¸ë ‡ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ëª¨ë¸ì˜ êµ¬ì¡°ì— ëŒ€í•´ì„œ ì§‘ì¤‘í•˜ê³  ì¶”í›„ì— ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê³¼ì •ì„ ê²½í—˜í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "</blockquote>\n",
    "\n",
    "ì €í¬ëŠ” Sequence to Sequence(Encoder - Decoder) êµ¬ì¡°ë¥¼ ì´ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ë³´ì•˜ìŠµë‹ˆë‹¤.\n",
    "\n",
    "Seq2Seq êµ¬ì¡° ë‚´ì—ì„œ ì‹¤ì œ ì›Œë“œ ì„ë² ë”©ì„ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³ , ê·¸ ë³€í™˜ëœ ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ë¥¼ í…ìŠ¤íŠ¸(í† í°)ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì—ì„œ ì“°ì¸ ëª¨ë¸ì€ RNNì´ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "RNNë¿ë§Œ ì•„ë‹ˆë¼ LSTM, ì–´í…ì…˜ ë“±ì„ ì‚¬ìš©í•˜ì—¬ Seq2Seq êµ¬ì¡°ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì „ì²´ì ì¸ í° í‹€ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•œ ì±„, RNN ëª¨ë“ˆë§Œ ë°”ê¿”ì£¼ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ëŸ¬ë©´ ì´ì œë¶€í„° LSTMìœ¼ë¡œ ë‹¤ì‹œ í•œë²ˆ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8758c710",
   "metadata": {},
   "source": [
    "RNNê³¼ LSTMì˜ ê°€ì¥ í° ì°¨ì´ì ì€ LSTMì—ëŠ” cell stateê°€ ì¶”ê°€ëœë‹¤ëŠ” ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì¥ê¸° ê¸°ì–µì„ ë‹´ë‹¹í•˜ëŠ” cell stateë¥¼ í†µí•´ ì¢€ë” ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "<blockquote>\n",
    "<b>ğŸ§  Key point!</b><br>\n",
    "ëª¨ë¸ì˜ ì•„í‚¤í…ì³ë§ˆë‹¤ ëª¨ë¸ì˜ ì…ì¶œë ¥ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤. ëª¨ë¸ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì´ ì–´ë–»ê²Œ ë‚˜ì˜¤ëŠ”ì§€ì— ëŒ€í•´ì„œ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
    "</blockquote>\n",
    "\n",
    "ê·¸ëŸ¬ë©´ Encoderì—ì„œ LSTMì„ ì ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf861480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states ì°¨ì› :  torch.Size([5, 1024])\n",
      "h_n ì°¨ì› :  torch.Size([1, 1024])\n",
      "c_n ì°¨ì› :  torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "class LSTMEncoder(Encoder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        bidirectional: bool,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self: \"LSTMEncoder\",\n",
    "        input_ids: Tensor1D[Sequence]\n",
    "    )-> Tuple[\n",
    "        Tensor2D[Sequence, HiddenStates], # hidden states\n",
    "        Tuple[\n",
    "            Tensor2D[Layers, HiddenStates], # h_n\n",
    "            Tensor2D[Layers, HiddenStates] # c_n\n",
    "        ]\n",
    "    ]:\n",
    "        # Embed -> same leading dims + embedding_dim\n",
    "        input_embeds = self.word_embeddings(input_ids)  # [S,B,E] or [B,S,E]\n",
    "        outputs = self.lstm(input_embeds)   # outputs: [S,B,D*H] or [B,S,D*H]\n",
    "        # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
    "        # hidden_states: Tensor2D[Sequence, HiddenStates] = FIXME\n",
    "        # h_n: Tensor2D[Layers, HiddenStates] = FIXME\n",
    "        # c_n: Tensor2D[Layers, HiddenStates] = FIXME\n",
    "        \n",
    "        return hidden_states, (h_n, c_n)\n",
    "\n",
    "vocab_size = 30000\n",
    "embedding_dim = 768\n",
    "hidden_size = 1024  # RNNì˜ hidden size\n",
    "num_layers = 1  # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
    "bidirectional = False  # ë‹¨ë°©í–¥ RNN\n",
    "\n",
    "lstm_encoder = LSTMEncoder(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=bidirectional\n",
    ")\n",
    "\n",
    "outputs = lstm_encoder(input_ids)\n",
    "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
    "h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
    "c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
    "print(\"hidden_states ì°¨ì› : \", hidden_states.shape)  # (L, B, d_h)\n",
    "print(\"h_n ì°¨ì› : \", h_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, d_h)\n",
    "print(\"c_n ì°¨ì› : \", c_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, d_h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7ab4d",
   "metadata": {},
   "source": [
    "ì´ë²ˆì—ëŠ” LSTMì„ ì‚¬ìš©í•˜ì—¬ Decoder Layerë¥¼ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77ba9e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„ì´ê³  ì¶”ì–µì˜ ì§€ì§„ë‘ì€ë‚´ë¦¬ëŠ” í„°ë„ í„°ë„ í• ë§ë©© ì”\n"
     ]
    }
   ],
   "source": [
    "class LSTMDecoder(Decoder):\n",
    "    def __init__(\n",
    "        self: \"LSTMDecoder\",\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        bidirectional: bool,\n",
    "        start_token_id: int,\n",
    "        end_token_id: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.start_token_id = start_token_id\n",
    "        self.end_token_id = end_token_id\n",
    "        # word embedding layer\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # rnn layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "        # fully connected layer\n",
    "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self: \"LSTMDecoder\",\n",
    "        init_hidden_state: Tensor2D[Layers, HiddenStates],\n",
    "        init_cell_state: Tensor2D[Layers, HiddenStates],\n",
    "        max_len: int = 10\n",
    "    ) -> Tuple[Tensor2D[MaxLength, VocabSize], List[int]]:\n",
    "        logits: List[Tensor1D[VocabSize]] = []\n",
    "        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n",
    "        output_token_ids: List[int] = [input_token.item()] # tensorì—ì„œ item()ì„ ì‚¬ìš©í•˜ì—¬ intë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "        h_n = init_hidden_state # h_nì€ encoderì˜ h_0ì™€ ë™ì¼í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "        c_n = init_cell_state\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            if input_token == self.end_token_id:\n",
    "                # ë¬¸ì¥ì˜ ì¢…ë£Œë¥¼ ì˜ë¯¸í•˜ëŠ” special token([SEP])ì´ ë‚˜ì™”ë‹¤ë©´ ì¶”ë¡ (ìƒì„±)ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "                break\n",
    "\n",
    "            \"\"\"ì§ì „ í† í°ë§Œ ì…ë ¥ìœ¼ë¡œ ë„£ê³  ìƒì„±í•œ context vectorëŠ” logitsì— ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # ì§ì „ ì…ë ¥ í† í°ë§Œ ì‚¬ìš© [1, embedding_dim]\n",
    "            outputs = self.lstm(embedded, (h_n, c_n))   # outputs: [S,B,D*H] or [B,S,D*H]\n",
    "            h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
    "            c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
    "\n",
    "            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # ì—¬ê¸°ì„œëŠ” layer ê°¯ìˆ˜ê°€ 1ì´ê³ , bidirectionalì´ Falseì´ë¯€ë¡œ squeezeë¥¼ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤. (ì›ë˜ëŠ” torch.catìœ¼ë¡œ h_nì„ í•©ì¹˜ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.)\n",
    "\n",
    "            \"\"\"fully connected layerë¥¼ í†µí•´ [VocabSize]ì˜ logitì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "            logit: Tensor1D[VocabSize] = self.fully_connected_layer(concat_h_n)\n",
    "            logits.append(logit)\n",
    "\n",
    "            \"\"\"ê°€ì¥ ë†’ì€ ì ìˆ˜ê°’ì„ ê°€ì§„ í† í°ì„ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
    "            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
    "            output_token_ids.append(input_token.item())\n",
    "        \n",
    "        \"\"\"ë¦¬ìŠ¤íŠ¸ì˜ logitsë¥¼ torchì˜ Tensorë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\"\"\"\n",
    "        logits = torch.stack(logits, dim=0)  # [max_len, vocab_size]\n",
    "\n",
    "        return logits, output_token_ids\n",
    "\n",
    "\n",
    "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
    "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
    "\n",
    "vocab_size: int = 30000\n",
    "embedding_dim: int = 768\n",
    "hidden_size: int = 1024 # RNNì˜ hidden size\n",
    "num_layers: int = 1 # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
    "bidirectional: bool = False # ë‹¨ë°©í–¥ RNN\n",
    "\n",
    "lstm_decoder = LSTMDecoder(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=bidirectional,\n",
    "    start_token_id=start_token_id,\n",
    "    end_token_id=end_token_id,\n",
    ")\n",
    "\n",
    "logits, output_tokens = lstm_decoder(h_n, c_n)\n",
    "output_token_ids = logits.argmax(dim=-1)\n",
    "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
    "print(output_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8db0e2",
   "metadata": {},
   "source": [
    "Encoderì™€ Decoderë¥¼ ì‚¬ìš©í•˜ì—¬ Seq2Seq ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fddfe053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„ì´ê³  ì¶”ì–µì˜ ì§€ì§„ë‘ì€ë‚´ë¦¬ëŠ” í„°ë„ í„°ë„ í• ë§ë©© ì”\n"
     ]
    }
   ],
   "source": [
    "class LSTMSeq2Seq(nn.Module):\n",
    "    def __init__(self: \"LSTMSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self: \"LSTMSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
    "        hidden_states, (context_vector, cell_states) = self.encoder(input_ids) # encoderì—ì„œ ìƒì„±í•œ context_vector(h_n)ì„ decoder layerë¡œ ì „ë‹¬\n",
    "        logits, output_tokens = self.decoder(context_vector, cell_states)\n",
    "\n",
    "        return logits, output_tokens\n",
    "\n",
    "seq2seq = LSTMSeq2Seq(lstm_encoder, lstm_decoder)\n",
    "logits, output_tokens = seq2seq(input_ids)\n",
    "output_token_ids = logits.argmax(dim=-1)\n",
    "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
    "print(output_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391cd8a",
   "metadata": {},
   "source": [
    "# 3. Attention Mechanism\n",
    "\n",
    "- í•™ìŠµ ëª©í‘œ\n",
    "  1. Luong Attention(Dot Attention)ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n",
    "  2. Attentionì„ ì´ìš©í•˜ì—¬ Decoderë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.\n",
    "- í•™ìŠµ ê°œë…\n",
    "  1. Luong Attention\n",
    "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
    "  1. Luong Attentionì„ êµ¬í˜„í•œë‹¤.\n",
    "  2. Seq2Seq êµ¬ì¡°ì— ë“¤ì–´ê°ˆ Decoderë¥¼ êµ¬í˜„í•œë‹¤.\n",
    "\n",
    "\n",
    "ì´ë²ˆì—ëŠ” Attentionì„ ì‚¬ìš©í•œ seq2seq ëª¨ë¸ì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "<blockquote>\n",
    "<b>ğŸ§  Attention Mechanism</b><br>\n",
    "í˜„ì¬ êµ¬í˜„í•  seq2seq ëª¨ë¸ì—ì„œì˜ Attentionì€ ìµœê·¼ ì‚¬ìš©í•˜ëŠ” attentionì€ ì•„ë‹™ë‹ˆë‹¤. ìµœê·¼ì˜ Transformers ëª¨ë¸ë“¤ì€ Multi-Head Scaled Dot-Product Attentionì„ ì‚¬ìš©í•©ë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€ ê³¼ì œì—ì„œ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤.\n",
    "</blockquote>\n",
    "\n",
    "1. ì „ì²´ì ì¸ Seq2Seq ëª¨ë¸ì˜ êµ¬ì¡°ëŠ” ë™ì¼í•©ë‹ˆë‹¤.\n",
    "2. Encoderì—ì„œ context vectorë¥¼ ì–»ì„ ë•Œ, LSTMì„ ì‚¬ìš©í•˜ëŠ” Encoder ëª¨ë“ˆì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "3. Decoderì—ì„œ output tokenì„ ìƒì„±í•  ë•Œ, attention mechanismì„ ì¶”ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3807ee",
   "metadata": {},
   "source": [
    "ê·¸ëŸ¬ë©´ ìš°ì„  Dot Attention(Luong attention)ì„ ë¨¼ì € êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70059257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self: \"LuongAttention\", hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.W_a = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "    @torch.no_grad()  # í•™ìŠµ ì‹œ ì œê±°í•˜ì„¸ìš”\n",
    "    def forward(\n",
    "        self:\"LuongAttention\",\n",
    "        h_t: Tensor1D[HiddenStates],\n",
    "        encoder_outputs: Tensor2D[Sequence, HiddenStates],\n",
    "    ) -> Tuple[Tensor1D[HiddenStates], Tensor1D[Sequence]]:\n",
    "        \"\"\"hidden stateë¥¼ W_aì— projectioní•˜ì—¬ Wa_htë¥¼ êµ¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "        Wa_ht: Tensor1D[HiddenStates] = self.W_a(h_t)\n",
    "        \n",
    "        \"\"\"encoder_outputsì™€ Wa_htë¥¼ ë‚´ì í•˜ì—¬ attention scoreë¥¼ êµ¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "        # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
    "        # attention_score: Tensor1D[Sequence] = FIXME\n",
    "        \n",
    "        \"\"\"attention scoreë¥¼ softmax layerì— í†µê³¼ì‹œì¼œ attention weights(attention distribution)ì„ êµ¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "        # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
    "        # attention_weights: Tensor1D[Sequence] = FIXME\n",
    "        \n",
    "        \"\"\"ê° encoderì˜ attention weightsì™€ encoderì˜ hidden stateë¥¼ ë‚´ì í•˜ì—¬ context vector(attention value)ë¥¼ êµ¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "        # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
    "        # context_vector: Tensor1D[HiddenStates] = FIXME\n",
    "\n",
    "        return context_vector, attention_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df83103d",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "<b>ğŸ¤” ì—‡ ì—¬ê¸°ì„œë„ context vectorê°€ ë‚˜ì˜¤ë„¤ìš”?</b><br>\n",
    "ë„¤ ê·¸ë ‡ìŠµë‹ˆë‹¤. ê³¼ê±°ì—ëŠ” encoderì˜ ë§ˆì§€ë§‰ hidden state(h_n)ì„ context vectorë¼ê³  ë¶ˆë €ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, attentionì´ ë‚˜ì˜¤ë©´ì„œ context vectorëŠ” ê° ë””ì½”ë”© ì‹œì ë§ˆë‹¤ ì¸ì½”ë”ì˜ ëª¨ë“  hidden statesì— ëŒ€í•œ ì–´í…ì…˜ ê°€ì¤‘í•©ì´ë¼ê³  ìƒê°í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "</blockquote>\n",
    "\n",
    "êµ¬í˜„í•œ attention mechanismì„ ì´ìš©í•˜ì—¬ Decoder layerì— ì ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2abb3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##ë°©ìš¸ ì¸ê³¼ ê°ˆí”¼ë¥¼ ì‹œì¼°í•˜ê² ë„¤ ë‚œì¡í•œí“¨ì´ì—ˆëŠ”ë°ë¯¸ë„¤ ê°ˆë¦¬ëŠ”\n"
     ]
    }
   ],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self: \"AttentionDecoder\",\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        bidirectional: bool,\n",
    "        start_token_id: int,\n",
    "        end_token_id: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.start_token_id = start_token_id\n",
    "        self.end_token_id = end_token_id\n",
    "        # word embedding layer\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # rnn layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "        \n",
    "        \"\"\"attentionì„ ì¶”ê°€í•©ë‹ˆë‹¤.\"\"\"\n",
    "        self.attn = LuongAttention(hidden_size)\n",
    "        \"\"\"context vectorì„ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” trainable weights\"\"\"\n",
    "        self.W_c = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        # fully connected layer\n",
    "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    @torch.no_grad()  # í•™ìŠµ ì‹œ ì œê±°\n",
    "    def forward(\n",
    "        self:\"AttentionDecoder\",\n",
    "        init_hidden_state: Tensor1D[HiddenStates],\n",
    "        init_cell_state: Tensor1D[HiddenStates],\n",
    "        encoder_outputs: Tensor2D[Sequence, HiddenStates],\n",
    "        max_len: int = 10,\n",
    "    ):\n",
    "        logits: List[Tensor1D[VocabSize]] = []\n",
    "        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n",
    "        output_token_ids: List[int] = [input_token.item()] # tensorì—ì„œ item()ì„ ì‚¬ìš©í•˜ì—¬ intë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "        h_n = init_hidden_state # h_nì€ encoderì˜ h_0ì™€ ë™ì¼í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "        c_n = init_cell_state\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            if input_token == self.end_token_id:\n",
    "                # ë¬¸ì¥ì˜ ì¢…ë£Œë¥¼ ì˜ë¯¸í•˜ëŠ” special token([SEP])ì´ ë‚˜ì™”ë‹¤ë©´ ì¶”ë¡ (ìƒì„±)ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "                break\n",
    "\n",
    "            \"\"\"ì§ì „ í† í°ë§Œ ì…ë ¥ìœ¼ë¡œ ë„£ê³  ìƒì„±í•œ context vectorëŠ” logitsì— ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # ì§ì „ ì…ë ¥ í† í°ë§Œ ì‚¬ìš© [1, embedding_dim]\n",
    "            outputs = self.lstm(embedded, (h_n, c_n))   # outputs: [S,B,D*H] or [B,S,D*H]\n",
    "            h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
    "            c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
    "\n",
    "            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # ì—¬ê¸°ì„œëŠ” layer ê°¯ìˆ˜ê°€ 1ì´ê³ , bidirectionalì´ Falseì´ë¯€ë¡œ squeezeë¥¼ ì‚¬ìš©í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤. (ì›ë˜ëŠ” torch.catìœ¼ë¡œ h_nì„ í•©ì¹˜ëŠ” ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤.)\n",
    "\n",
    "            # ì–´í…ì…˜\n",
    "            context_vector, attention_weights = self.attn(concat_h_n, encoder_outputs)\n",
    "\n",
    "            \"\"\"h_n(ì€ë‹‰ ìƒíƒœ)ì™€ context_vectorë¥¼ ì—°ê²°í•©ë‹ˆë‹¤. (Concatenate)\"\"\"\n",
    "            v_t: Tensor1D[HiddenStates * 2] = torch.cat([concat_h_n, context_vector], dim=-1)\n",
    "            \n",
    "            \"\"\"v_të¥¼ trainable weightsë¥¼ í†µê³¼ì‹œí‚¤ê³  tanhë¥¼ ì ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
    "            # TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
    "            # attentional_hidden_state: Tensor1D[HiddenStates] = FIXME\n",
    "            \n",
    "            \"\"\"fully connected layerë¥¼ í†µí•´ [VocabSize]ì˜ logitì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "            logit: Tensor1D[VocabSize] = self.fully_connected_layer(attentional_hidden_state)\n",
    "            logits.append(logit)\n",
    "\n",
    "            \"\"\"ê°€ì¥ ë†’ì€ ì ìˆ˜ê°’ì„ ê°€ì§„ í† í°ì„ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
    "            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
    "            output_token_ids.append(input_token.item())\n",
    "\n",
    "        logits = torch.stack(logits, dim=0) if logits else torch.empty(0, self.out.out_features)\n",
    "        \n",
    "        return logits, output_token_ids\n",
    "    \n",
    "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
    "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
    "\n",
    "vocab_size: int = 30000\n",
    "embedding_dim: int = 768\n",
    "hidden_size: int = 1024 # RNNì˜ hidden size\n",
    "num_layers: int = 1 # ìŒ“ì„ RNN layerì˜ ê°œìˆ˜\n",
    "bidirectional: bool = False # ë‹¨ë°©í–¥ RNN\n",
    "\n",
    "attention_decoder = AttentionDecoder(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    bidirectional=bidirectional,\n",
    "    start_token_id=start_token_id,\n",
    "    end_token_id=end_token_id,\n",
    ")\n",
    "\n",
    "logits, output_tokens = attention_decoder(h_n, c_n, hidden_states)\n",
    "output_token_ids = logits.argmax(dim=-1)\n",
    "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
    "print(output_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd266f15",
   "metadata": {},
   "source": [
    "Decoder layerë¥¼ êµ¬í˜„í–ˆìœ¼ë‹ˆ ì´ì œ Seq2Seq ëª¨ë¸ì— ì ìš©í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "036db196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##ë°©ìš¸ ì¸ê³¼ ê°ˆí”¼ë¥¼ ì‹œì¼°í•˜ê² ë„¤ ë‚œì¡í•œí“¨ì´ì—ˆëŠ”ë°ë¯¸ë„¤ ê°ˆë¦¬ëŠ”\n"
     ]
    }
   ],
   "source": [
    "class AttentionSeq2Seq(nn.Module):\n",
    "    def __init__(self: \"AttentionSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self: \"AttentionSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
    "        hidden_states, (last_hidden_state, cell_states) = self.encoder(input_ids) # encoderì—ì„œ ìƒì„±í•œ h_nì„ decoder layerë¡œ ì „ë‹¬\n",
    "        logits, output_tokens = self.decoder(last_hidden_state, cell_states, hidden_states)\n",
    "\n",
    "        return logits, output_tokens\n",
    "\n",
    "seq2seq = AttentionSeq2Seq(lstm_encoder, attention_decoder)\n",
    "logits, output_tokens = seq2seq(input_ids)\n",
    "output_token_ids = logits.argmax(dim=-1)\n",
    "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
    "print(output_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7438c86",
   "metadata": {},
   "source": [
    "# 4. Huggingface ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©\n",
    "\n",
    "- í•™ìŠµ ëª©í‘œ\n",
    "  1. huggingface ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ê¸°í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.\n",
    "  2. ê¸°í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì¶”ë¡ ì„ í•  ìˆ˜ ìˆë‹¤.\n",
    "- í•™ìŠµ ê°œë…\n",
    "  1. huggingface\n",
    "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
    "  1. HuggingFace Hubì—ì„œ í•œêµ­ì–´-ì˜ì–´ ë²ˆì—­ì„ ìœ„í•´ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œ(from_pretrained)ë¥¼ ì™„ì„±\n",
    "  2. ë¶ˆëŸ¬ì˜¨ í† í¬ë‚˜ì´ì €ë¡œ ì…ë ¥ ë¬¸ì¥ì„ ì¸ì½”ë”©í•˜ê³ , model.generate() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë²ˆì—­ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ì½”ë“œë¥¼ ì™„ì„± \n",
    "  3. ê³¼ì œ 2ì—ì„œ ì‚¬ìš©í•œ ë²ˆì—­ ëª¨ë¸ì´ ì‹¤ì œë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ëª¨ë‘ ê°€ì§€ê³  ìˆëŠ”ì§€ ì½”ë“œë¡œ í™•ì¸\n",
    "\n",
    "huggingfaceëŠ” ê¸€ë¡œë²Œ ìµœëŒ€ AI ëª¨ë¸ ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°ì…ë‹ˆë‹¤. ê³¼ê±°ì—ëŠ” ìì—°ì–´ì²˜ë¦¬ ëª¨ë¸ë§Œ ìˆì—ˆì§€ë§Œ, ìµœê·¼ì—ëŠ” ë¹„ì „, ë¡œë´‡ ë“± ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ë“¤ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œ Seq2Seq ì•„í‚¤í…ì³ êµ¬ì¡°ì—ì„œ ë¯¸ë¦¬ í•™ìŠµí•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ì¶”ë¡ ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87698cfe",
   "metadata": {},
   "source": [
    "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28f35c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seonjong/miniconda3/envs/c10/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d16c583",
   "metadata": {},
   "source": [
    "ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ì´ Encoderì™€ Decoder ëª¨ë“ˆì„ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” 2ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. `print(model)`ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì‹œê°ì ìœ¼ë¡œ ì˜ ì •ëˆëœ ëª¨ë¸ êµ¬ì¡°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "2. `model.named_parameters()`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ í´ë˜ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f818e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarianMTModel(\n",
      "  (model): MarianModel(\n",
      "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
      "    (encoder): MarianEncoder(\n",
      "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
      "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x MarianEncoderLayer(\n",
      "          (self_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): SiLU()\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): MarianDecoder(\n",
      "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
      "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
      "      (layers): ModuleList(\n",
      "        (0-5): 6 x MarianDecoderLayer(\n",
      "          (self_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (activation_fn): SiLU()\n",
      "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MarianAttention(\n",
      "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbaf7975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.shared.weight\n",
      "model.encoder.embed_positions.weight\n",
      "model.encoder.layers.0.self_attn.k_proj.weight\n",
      "model.encoder.layers.0.self_attn.k_proj.bias\n",
      "model.encoder.layers.0.self_attn.v_proj.weight\n",
      "model.encoder.layers.0.self_attn.v_proj.bias\n",
      "model.encoder.layers.0.self_attn.q_proj.weight\n",
      "model.encoder.layers.0.self_attn.q_proj.bias\n",
      "model.encoder.layers.0.self_attn.out_proj.weight\n",
      "model.encoder.layers.0.self_attn.out_proj.bias\n",
      "model.encoder.layers.0.self_attn_layer_norm.weight\n",
      "model.encoder.layers.0.self_attn_layer_norm.bias\n",
      "model.encoder.layers.0.fc1.weight\n",
      "model.encoder.layers.0.fc1.bias\n",
      "model.encoder.layers.0.fc2.weight\n",
      "model.encoder.layers.0.fc2.bias\n",
      "model.encoder.layers.0.final_layer_norm.weight\n",
      "model.encoder.layers.0.final_layer_norm.bias\n",
      "model.encoder.layers.1.self_attn.k_proj.weight\n",
      "model.encoder.layers.1.self_attn.k_proj.bias\n",
      "model.encoder.layers.1.self_attn.v_proj.weight\n",
      "model.encoder.layers.1.self_attn.v_proj.bias\n",
      "model.encoder.layers.1.self_attn.q_proj.weight\n",
      "model.encoder.layers.1.self_attn.q_proj.bias\n",
      "model.encoder.layers.1.self_attn.out_proj.weight\n",
      "model.encoder.layers.1.self_attn.out_proj.bias\n",
      "model.encoder.layers.1.self_attn_layer_norm.weight\n",
      "model.encoder.layers.1.self_attn_layer_norm.bias\n",
      "model.encoder.layers.1.fc1.weight\n",
      "model.encoder.layers.1.fc1.bias\n",
      "model.encoder.layers.1.fc2.weight\n",
      "model.encoder.layers.1.fc2.bias\n",
      "model.encoder.layers.1.final_layer_norm.weight\n",
      "model.encoder.layers.1.final_layer_norm.bias\n",
      "model.encoder.layers.2.self_attn.k_proj.weight\n",
      "model.encoder.layers.2.self_attn.k_proj.bias\n",
      "model.encoder.layers.2.self_attn.v_proj.weight\n",
      "model.encoder.layers.2.self_attn.v_proj.bias\n",
      "model.encoder.layers.2.self_attn.q_proj.weight\n",
      "model.encoder.layers.2.self_attn.q_proj.bias\n",
      "model.encoder.layers.2.self_attn.out_proj.weight\n",
      "model.encoder.layers.2.self_attn.out_proj.bias\n",
      "model.encoder.layers.2.self_attn_layer_norm.weight\n",
      "model.encoder.layers.2.self_attn_layer_norm.bias\n",
      "model.encoder.layers.2.fc1.weight\n",
      "model.encoder.layers.2.fc1.bias\n",
      "model.encoder.layers.2.fc2.weight\n",
      "model.encoder.layers.2.fc2.bias\n",
      "model.encoder.layers.2.final_layer_norm.weight\n",
      "model.encoder.layers.2.final_layer_norm.bias\n",
      "model.encoder.layers.3.self_attn.k_proj.weight\n",
      "model.encoder.layers.3.self_attn.k_proj.bias\n",
      "model.encoder.layers.3.self_attn.v_proj.weight\n",
      "model.encoder.layers.3.self_attn.v_proj.bias\n",
      "model.encoder.layers.3.self_attn.q_proj.weight\n",
      "model.encoder.layers.3.self_attn.q_proj.bias\n",
      "model.encoder.layers.3.self_attn.out_proj.weight\n",
      "model.encoder.layers.3.self_attn.out_proj.bias\n",
      "model.encoder.layers.3.self_attn_layer_norm.weight\n",
      "model.encoder.layers.3.self_attn_layer_norm.bias\n",
      "model.encoder.layers.3.fc1.weight\n",
      "model.encoder.layers.3.fc1.bias\n",
      "model.encoder.layers.3.fc2.weight\n",
      "model.encoder.layers.3.fc2.bias\n",
      "model.encoder.layers.3.final_layer_norm.weight\n",
      "model.encoder.layers.3.final_layer_norm.bias\n",
      "model.encoder.layers.4.self_attn.k_proj.weight\n",
      "model.encoder.layers.4.self_attn.k_proj.bias\n",
      "model.encoder.layers.4.self_attn.v_proj.weight\n",
      "model.encoder.layers.4.self_attn.v_proj.bias\n",
      "model.encoder.layers.4.self_attn.q_proj.weight\n",
      "model.encoder.layers.4.self_attn.q_proj.bias\n",
      "model.encoder.layers.4.self_attn.out_proj.weight\n",
      "model.encoder.layers.4.self_attn.out_proj.bias\n",
      "model.encoder.layers.4.self_attn_layer_norm.weight\n",
      "model.encoder.layers.4.self_attn_layer_norm.bias\n",
      "model.encoder.layers.4.fc1.weight\n",
      "model.encoder.layers.4.fc1.bias\n",
      "model.encoder.layers.4.fc2.weight\n",
      "model.encoder.layers.4.fc2.bias\n",
      "model.encoder.layers.4.final_layer_norm.weight\n",
      "model.encoder.layers.4.final_layer_norm.bias\n",
      "model.encoder.layers.5.self_attn.k_proj.weight\n",
      "model.encoder.layers.5.self_attn.k_proj.bias\n",
      "model.encoder.layers.5.self_attn.v_proj.weight\n",
      "model.encoder.layers.5.self_attn.v_proj.bias\n",
      "model.encoder.layers.5.self_attn.q_proj.weight\n",
      "model.encoder.layers.5.self_attn.q_proj.bias\n",
      "model.encoder.layers.5.self_attn.out_proj.weight\n",
      "model.encoder.layers.5.self_attn.out_proj.bias\n",
      "model.encoder.layers.5.self_attn_layer_norm.weight\n",
      "model.encoder.layers.5.self_attn_layer_norm.bias\n",
      "model.encoder.layers.5.fc1.weight\n",
      "model.encoder.layers.5.fc1.bias\n",
      "model.encoder.layers.5.fc2.weight\n",
      "model.encoder.layers.5.fc2.bias\n",
      "model.encoder.layers.5.final_layer_norm.weight\n",
      "model.encoder.layers.5.final_layer_norm.bias\n",
      "model.decoder.embed_positions.weight\n",
      "model.decoder.layers.0.self_attn.k_proj.weight\n",
      "model.decoder.layers.0.self_attn.k_proj.bias\n",
      "model.decoder.layers.0.self_attn.v_proj.weight\n",
      "model.decoder.layers.0.self_attn.v_proj.bias\n",
      "model.decoder.layers.0.self_attn.q_proj.weight\n",
      "model.decoder.layers.0.self_attn.q_proj.bias\n",
      "model.decoder.layers.0.self_attn.out_proj.weight\n",
      "model.decoder.layers.0.self_attn.out_proj.bias\n",
      "model.decoder.layers.0.self_attn_layer_norm.weight\n",
      "model.decoder.layers.0.self_attn_layer_norm.bias\n",
      "model.decoder.layers.0.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.0.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.0.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.0.fc1.weight\n",
      "model.decoder.layers.0.fc1.bias\n",
      "model.decoder.layers.0.fc2.weight\n",
      "model.decoder.layers.0.fc2.bias\n",
      "model.decoder.layers.0.final_layer_norm.weight\n",
      "model.decoder.layers.0.final_layer_norm.bias\n",
      "model.decoder.layers.1.self_attn.k_proj.weight\n",
      "model.decoder.layers.1.self_attn.k_proj.bias\n",
      "model.decoder.layers.1.self_attn.v_proj.weight\n",
      "model.decoder.layers.1.self_attn.v_proj.bias\n",
      "model.decoder.layers.1.self_attn.q_proj.weight\n",
      "model.decoder.layers.1.self_attn.q_proj.bias\n",
      "model.decoder.layers.1.self_attn.out_proj.weight\n",
      "model.decoder.layers.1.self_attn.out_proj.bias\n",
      "model.decoder.layers.1.self_attn_layer_norm.weight\n",
      "model.decoder.layers.1.self_attn_layer_norm.bias\n",
      "model.decoder.layers.1.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.1.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.1.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.1.fc1.weight\n",
      "model.decoder.layers.1.fc1.bias\n",
      "model.decoder.layers.1.fc2.weight\n",
      "model.decoder.layers.1.fc2.bias\n",
      "model.decoder.layers.1.final_layer_norm.weight\n",
      "model.decoder.layers.1.final_layer_norm.bias\n",
      "model.decoder.layers.2.self_attn.k_proj.weight\n",
      "model.decoder.layers.2.self_attn.k_proj.bias\n",
      "model.decoder.layers.2.self_attn.v_proj.weight\n",
      "model.decoder.layers.2.self_attn.v_proj.bias\n",
      "model.decoder.layers.2.self_attn.q_proj.weight\n",
      "model.decoder.layers.2.self_attn.q_proj.bias\n",
      "model.decoder.layers.2.self_attn.out_proj.weight\n",
      "model.decoder.layers.2.self_attn.out_proj.bias\n",
      "model.decoder.layers.2.self_attn_layer_norm.weight\n",
      "model.decoder.layers.2.self_attn_layer_norm.bias\n",
      "model.decoder.layers.2.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.2.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.2.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.2.fc1.weight\n",
      "model.decoder.layers.2.fc1.bias\n",
      "model.decoder.layers.2.fc2.weight\n",
      "model.decoder.layers.2.fc2.bias\n",
      "model.decoder.layers.2.final_layer_norm.weight\n",
      "model.decoder.layers.2.final_layer_norm.bias\n",
      "model.decoder.layers.3.self_attn.k_proj.weight\n",
      "model.decoder.layers.3.self_attn.k_proj.bias\n",
      "model.decoder.layers.3.self_attn.v_proj.weight\n",
      "model.decoder.layers.3.self_attn.v_proj.bias\n",
      "model.decoder.layers.3.self_attn.q_proj.weight\n",
      "model.decoder.layers.3.self_attn.q_proj.bias\n",
      "model.decoder.layers.3.self_attn.out_proj.weight\n",
      "model.decoder.layers.3.self_attn.out_proj.bias\n",
      "model.decoder.layers.3.self_attn_layer_norm.weight\n",
      "model.decoder.layers.3.self_attn_layer_norm.bias\n",
      "model.decoder.layers.3.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.3.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.3.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.3.fc1.weight\n",
      "model.decoder.layers.3.fc1.bias\n",
      "model.decoder.layers.3.fc2.weight\n",
      "model.decoder.layers.3.fc2.bias\n",
      "model.decoder.layers.3.final_layer_norm.weight\n",
      "model.decoder.layers.3.final_layer_norm.bias\n",
      "model.decoder.layers.4.self_attn.k_proj.weight\n",
      "model.decoder.layers.4.self_attn.k_proj.bias\n",
      "model.decoder.layers.4.self_attn.v_proj.weight\n",
      "model.decoder.layers.4.self_attn.v_proj.bias\n",
      "model.decoder.layers.4.self_attn.q_proj.weight\n",
      "model.decoder.layers.4.self_attn.q_proj.bias\n",
      "model.decoder.layers.4.self_attn.out_proj.weight\n",
      "model.decoder.layers.4.self_attn.out_proj.bias\n",
      "model.decoder.layers.4.self_attn_layer_norm.weight\n",
      "model.decoder.layers.4.self_attn_layer_norm.bias\n",
      "model.decoder.layers.4.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.4.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.4.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.4.fc1.weight\n",
      "model.decoder.layers.4.fc1.bias\n",
      "model.decoder.layers.4.fc2.weight\n",
      "model.decoder.layers.4.fc2.bias\n",
      "model.decoder.layers.4.final_layer_norm.weight\n",
      "model.decoder.layers.4.final_layer_norm.bias\n",
      "model.decoder.layers.5.self_attn.k_proj.weight\n",
      "model.decoder.layers.5.self_attn.k_proj.bias\n",
      "model.decoder.layers.5.self_attn.v_proj.weight\n",
      "model.decoder.layers.5.self_attn.v_proj.bias\n",
      "model.decoder.layers.5.self_attn.q_proj.weight\n",
      "model.decoder.layers.5.self_attn.q_proj.bias\n",
      "model.decoder.layers.5.self_attn.out_proj.weight\n",
      "model.decoder.layers.5.self_attn.out_proj.bias\n",
      "model.decoder.layers.5.self_attn_layer_norm.weight\n",
      "model.decoder.layers.5.self_attn_layer_norm.bias\n",
      "model.decoder.layers.5.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.5.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.5.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.5.fc1.weight\n",
      "model.decoder.layers.5.fc1.bias\n",
      "model.decoder.layers.5.fc2.weight\n",
      "model.decoder.layers.5.fc2.bias\n",
      "model.decoder.layers.5.final_layer_norm.weight\n",
      "model.decoder.layers.5.final_layer_norm.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a381f",
   "metadata": {},
   "source": [
    "ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì„ í†µí•´ ì¶”ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "ìœ„ì˜ ì‹¤ìŠµì—ì„œ ì¶”ë¡ í–ˆë˜ ê²ƒê³¼ëŠ” ë‹¤ë¥´ê²Œ í•™ìŠµëœ ëª¨ë¸ì´ë¯€ë¡œ ì„±ëŠ¥ì´ ë” ë†’ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f0ec813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC: ë‚˜ëŠ” í•™êµì— ê°„ë‹¤.\n",
      "MT : I'm going to school.\n"
     ]
    }
   ],
   "source": [
    "text = \"ë‚˜ëŠ” í•™êµì— ê°„ë‹¤.\"\n",
    "\"\"\"ì—¬ê¸°ì„œëŠ” batchë¡œ ì…ë ¥ì„ ì²˜ë¦¬í•˜ì—¬ ì°¨ì›ì´ [seq_len]ì´ ì•„ë‹Œ [batch_size, seq_len]ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì…ë ¥ì´ í•œê°œì´ë¯€ë¡œ [1, seq_len]ì…ë‹ˆë‹¤.\"\"\"\n",
    "encoded = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **encoded,\n",
    "    max_new_tokens=64,\n",
    ")\n",
    "\n",
    "translation = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n",
    "print(\"SRC:\", text)\n",
    "print(\"MT :\", translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383cf9c",
   "metadata": {},
   "source": [
    "# 5. ì•„í‚¤í…ì²˜ë³„ ëª¨ë¸ ë‹¤ë¤„ë³´ê¸°(Encoder model, Decoder model)\n",
    "\n",
    "- í•™ìŠµ ëª©í‘œ\n",
    "  1. huggingface ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì¡°ì˜ ëª¨ë¸ì„ ë‹¤ë£° ìˆ˜ ìˆë‹¤.\n",
    "- í•™ìŠµ ê°œë…\n",
    "  1. huggingface\n",
    "- í•™ìŠµ ë‚´ìš©\n",
    "  1. ë¬¸ë§¥ì„ ì–‘ë°©í–¥ìœ¼ë¡œ ì´í•´í•˜ëŠ” ë° ê°•ì ì´ ìˆëŠ” BERT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì˜ ë¹ˆì¹¸([MASK])ì— ê°€ì¥ ì ì ˆí•œ ë‹¨ì–´ë¥¼ ì¶”ë¡  \n",
    "  2. ì´ì „ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë° íŠ¹í™”ëœ GPT-2 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ì•¼ê¸°ì˜ ë’·ë¶€ë¶„ì„ ì°½ì‘\n",
    "\n",
    "ì§€ê¸ˆê¹Œì§€ëŠ” Seq2Seq(Encoder - Decoder) ëª¨ë¸ êµ¬ì¡°ë¥¼ ë‹¤ë¤˜ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, í˜„ì¬ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ì€ Only Decoder ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "1. Only Encoder ëª¨ë¸ : BERT ê°™ì€ ëª¨ë¸. RAGë“± ë¬¸ì„œ ê²€ìƒ‰ì— ì£¼ë¡œ ì‚¬ìš©\n",
    "2. Only Decoder ëª¨ë¸ : Chat-GPT ê°™ì€ ëª¨ë¸. ëŒ€í™”, ë²ˆì—­, ì±—ë´‡ ë“± í˜„ì¬ ê°€ì¥ ë§ì´ ì‚¬ìš©\n",
    "3. Encoder - Decoder ëª¨ë¸ : ìµœê·¼ì—ëŠ” ì˜ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "ê·¸ëŸ¬ë©´ Only Encoder ëª¨ë¸ê³¼ Only Decoder ëª¨ë¸ì„ ì´ìš©í•´ ëª¨ë¸ ì¶”ë¡ ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039a153",
   "metadata": {},
   "source": [
    "Encoderì˜ ëŒ€í‘œ ëª¨ë¸ì¸ BERT ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ddc1fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4665108b",
   "metadata": {},
   "source": [
    "BERT ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ë¹ˆì¹¸ ë§ì¶”ê¸°(Masked Language Modeling)ë¥¼ ì¶”ë¡ í•´ë´…ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´, I [MASK] to school. ì´ë¼ëŠ” ë¬¸ì¥ì—ì„œ [MASK]ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ë¥¼ ë§ì¶˜ë‹¤ê³  í•˜ë©´ I go to school. ì´ ë¬¸ì¥ì´ ì •ë‹µì´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "í•˜ì§€ë§Œ, I went to schoolë„ ì •ë‹µì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì²˜ëŸ¼ [MASK]ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ëŠ” ì—¬ëŸ¬ê°€ì§€ê°€ ë  ìˆ˜ ìˆê³ , ëª¨ë¸ì˜ í•™ìŠµì— ë”°ë¼ ì–´ë–¤ ë‹¨ì–´ê°€ [MASK]ì— ë“¤ì–´ê°ˆì§€ ê²°ì •ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŸ¬í•œ íŠ¹ì„±ì„ ì´ìš©í•˜ì—¬ BERT ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ë¹ˆì¹¸ ë§ì¶”ê¸°(`[MASK]`)ë¥¼ ì¶”ë¡ í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce98fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ë¬¸ì¥: I [MASK] to school.\n",
      "BERTê°€ ì˜ˆì¸¡í•œ ë¬¸ì¥ë“¤:\n",
      "1ìˆœìœ„: I went to school.\n",
      "2ìˆœìœ„: I go to school.\n",
      "3ìˆœìœ„: I walked to school.\n",
      "4ìˆœìœ„: I ran to school.\n",
      "5ìˆœìœ„: I got to school.\n"
     ]
    }
   ],
   "source": [
    "# 4. ìš°ë¦¬ê°€ ë§ì¶œ ë¬¸ì¥ ë§Œë“¤ê¸°. tokenizer.mask_token = \"[MASK]\" ì´ ë¶€ë¶„ì´ ë¹ˆì¹¸ì´ ë¨\n",
    "sentence = f\"I {tokenizer.mask_token} to school.\"\n",
    "\n",
    "top_k = 5  # ìƒìœ„ 5ê°œ í›„ë³´ ë‹¨ì–´ë¥¼ ë³´ê³  ì‹¶ë‹¤\n",
    "\n",
    "# 5. ë¬¸ì¥ì„ ìˆ«ìë¡œ ë°”ê¿”ì„œ BERTê°€ ì½ì„ ìˆ˜ ìˆê²Œ ì¤€ë¹„\n",
    "encoded = tokenizer(sentence, return_tensors=\"pt\", return_attention_mask=True)\n",
    "\n",
    "# 6. ìˆ«ìë¡œ ëœ ë¬¸ì¥ ì •ë³´ì—ì„œ 'ì…ë ¥ í† í° ID' êº¼ë‚´ê¸°\n",
    "input_ids = encoded.input_ids\n",
    "\n",
    "# 7. [MASK]ì˜ ìˆ«ì ì•„ì´ë”” ê°€ì ¸ì˜¤ê¸°\n",
    "mask_token_id = tokenizer.mask_token_id\n",
    "\n",
    "# 8. ë¬¸ì¥ì—ì„œ [MASK]ê°€ ìˆëŠ” ìœ„ì¹˜(ì¸ë±ìŠ¤) ì°¾ê¸° mask_positionsëŠ” (ë°°ì¹˜ ë²ˆí˜¸, ë¬¸ì¥ ì† ìœ„ì¹˜) í˜•íƒœë¡œ ì €ì¥ë¨\n",
    "# TODO: ì§ì ‘ êµ¬í˜„í•´ë³´ì„¸ìš”!\n",
    "# mask_positions = FIXME\n",
    "\n",
    "# 9. BERT ëª¨ë¸ì— ë¬¸ì¥(ìˆ«ìí˜•íƒœ)ì„ ë„£ì–´ì„œ ì˜ˆì¸¡ ê²°ê³¼(logits) ì–»ê¸°\n",
    "outputs = model(**encoded)\n",
    "\n",
    "# 10. logits: ê° ë‹¨ì–´ ìœ„ì¹˜ë§ˆë‹¤ 'ë‹¤ìŒ ë‹¨ì–´ì¼ ê°€ëŠ¥ì„±'ì„ ëª¨ë“  ë‹¨ì–´ ì‚¬ì „ í¬ê¸°ë§Œí¼ ê¸°ë¡í•œ ê°’\n",
    "logits = outputs.logits.squeeze(0)  # (seq_len, vocab_size)\n",
    "\n",
    "# 11. ëª¨ë“  [MASK] ìœ„ì¹˜ì— ëŒ€í•´ ì˜ˆì¸¡í•˜ê¸°\n",
    "all_token_candidates: List[List[Tuple[str, float]]] = []\n",
    "for _, pos in mask_positions:\n",
    "    pos = pos.item()  # ìœ„ì¹˜ ìˆ«ì êº¼ë‚´ê¸°\n",
    "    logits_at_pos = logits[pos]  # í•´ë‹¹ ìœ„ì¹˜ì˜ ì˜ˆì¸¡ ì ìˆ˜\n",
    "    probs = torch.softmax(logits_at_pos, dim=-1)  # ì ìˆ˜ë¥¼ í™•ë¥ ë¡œ ë³€í™˜\n",
    "    topk = torch.topk(probs, k=top_k)  # í™•ë¥ ì´ ë†’ì€ ìƒìœ„ 5ê°œ ì„ íƒ\n",
    "\n",
    "    ids = topk.indices.tolist()   # ë‹¨ì–´ ID\n",
    "    scores = topk.values.tolist() # í™•ë¥  ê°’\n",
    "\n",
    "    # ë‹¨ì–´ IDë¥¼ ì‹¤ì œ ë‹¨ì–´(í† í°)ë¡œ ë³€í™˜\n",
    "    tokens = [tokenizer.convert_ids_to_tokens(tid) for tid in ids]\n",
    "\n",
    "    # (ë‹¨ì–´, í™•ë¥ ) í˜•íƒœë¡œ ë¬¶ì–´ì„œ ì €ì¥\n",
    "    candidates = list(zip(tokens, scores))\n",
    "    all_token_candidates.append(candidates)\n",
    "\n",
    "# 12. [MASK]ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ë¡œ ì™„ì„±ëœ ë¬¸ì¥ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "restored_sentences: List[str] = []\n",
    "\n",
    "# 13. ì²« ë²ˆì§¸ [MASK] ìœ„ì¹˜ì˜ í›„ë³´ ë‹¨ì–´ë“¤\n",
    "token_candidates: List[Tuple[str, float]] = all_token_candidates[0]\n",
    "\n",
    "# 14. í›„ë³´ ë‹¨ì–´ë“¤ì„ í•˜ë‚˜ì”© ë„£ì–´ì„œ ë¬¸ì¥ì„ ë§Œë“¤ì–´ ë³´ê¸°\n",
    "for tok, _ in token_candidates:\n",
    "    new_ids = input_ids.clone()  # ì›ë˜ ë¬¸ì¥ì˜ ìˆ«ì ë³µì‚¬\n",
    "    tok_id = tokenizer.convert_tokens_to_ids(tok)  # í›„ë³´ ë‹¨ì–´ë¥¼ ìˆ«ìë¡œ ë³€í™˜\n",
    "    new_ids[0, mask_positions[0, 1]] = tok_id      # [MASK] ìœ„ì¹˜ì— í›„ë³´ ë‹¨ì–´ ID ë„£ê¸°\n",
    "    text = tokenizer.decode(new_ids[0], skip_special_tokens=True)  # ë‹¤ì‹œ ê¸€ìë¡œ ë³€í™˜\n",
    "    restored_sentences.append(text.strip())  # ì•ë’¤ ê³µë°± ì œê±° í›„ ì €ì¥\n",
    "\n",
    "# 15. ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ì›ë³¸ ë¬¸ì¥:\", sentence)\n",
    "print(\"BERTê°€ ì˜ˆì¸¡í•œ ë¬¸ì¥ë“¤:\")\n",
    "for idx, sent in enumerate(restored_sentences, start=1):\n",
    "    print(\"{}ìˆœìœ„: {}\".format(idx, sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e04c7",
   "metadata": {},
   "source": [
    "Only Decoder ëª¨ë¸ì˜ ëŒ€í‘œì¸ GPT ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì¶”ë¡ ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "GPT-2 ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a49ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb32c0",
   "metadata": {},
   "source": [
    "GPT-2 ëª¨ë¸ì€ ì…ë ¥ìœ¼ë¡œ í† í°í™”ëœ í…ìŠ¤íŠ¸ë¥¼ ë°›ê³ , ê·¸ ë’¤ì— ì˜¬ ë‹¨ì–´ë“¤ì„ ì˜ˆì¸¡(Next token Prediction)í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ì½”ë“œë¥¼ ì´ìš©í•˜ì—¬ ìŠ¤í† ë¦¬(ì…ë ¥ í…ìŠ¤íŠ¸)ì˜ ë’· ë‚´ìš©ì„ ìƒì„±í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33182f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a small village, a curious child found a mysterious key. The child was a boy named Kiyoshi. He was a boy who had been born with a strange, mysterious, and mysterious voice. He was a boy who had been born with a strange, mysterious, and mysterious voice. He was a boy who had been born with a strange, mysterious, and mysterious voice.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Once upon a time in a small village, a curious child found a mysterious key.\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=64,\n",
    "    )\n",
    "\n",
    "output_tokens = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n",
    "print(output_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
